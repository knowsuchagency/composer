{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Orkestra # deploy lambdas, compose them into workflows, and trigger them on schedule or from cloud events with ease (at a tiny fraction of the cost of Airflow) render your diagrams dynamically from code (like Airflow) no more wondering about the status of your jobs (and how they broke) no more struggling with the operational maintenance of always-on infrastructure to run your jobs What is Orkestra? # Orkestra is a lightweight abstraction layer on top of AWS Cloud Development Kit (CDK) Lambda Step Functions X-Ray Lambda Powertools (optionally) that provides a seamless way of building observable (scheduled or event-driven) cloud-native workflows. It aims to bring a similar development experience to that of Airflow while leveraging the full power of AWS. Features # simple intuitive developer experience scheduled (ETL) workflows event-driven workflows simplified local testing natively integrated with AWS cost-effective highly scalable Example # Business Logic 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 import random from typing import * from uuid import uuid4 from aws_lambda_powertools import Logger , Tracer from pydantic import BaseModel from orkestra import compose from orkestra.interfaces import Duration class Item ( BaseModel ): id : str name : str price : Optional [ float ] = None @classmethod def random ( cls ): return cls ( id = str ( uuid4 ()), name = random . choice ( [ \"potato\" , \"moon rock\" , \"hat\" , ] ), ) logger = Logger () tracer = Tracer () default_args = dict ( enable_powertools = True , timeout = Duration . seconds ( 6 ), ) @compose ( ** default_args ) def generate_item ( event , context ): logger . info ( \"generating random item\" ) item = Item . random () . dict () logger . info ( item ) tracer . put_metadata ( \"GenerateItem\" , \"SUCCESS\" ) return item @compose ( model = Item , ** default_args ) def add_price ( item : Item , context ): price = 3.14 logger . info ( \"adding price to item\" , extra = { \"item\" : item . dict (), \"price\" : price } ) item . price = price return item . dict () @compose ( model = Item , ** default_args ) def copy_item ( item : Item , context ) -> list : logger . info ( item . dict ()) return [ item . dict ()] * 10 @compose ( model = Item , is_map_job = True , ** default_args ) def double_price ( item : Item , context ): item . price = item . price * 2 return item . dict () @compose ( ** default_args ) def assert_false ( event , context ): assert False @compose ( ** default_args ) def do_nothing ( event , context ): logger . info ({ \"doing\" : \"nothing\" }) @compose ( ** default_args ) def say_hello ( event , context ): return \"hello, world\" @compose ( ** default_args ) def say_goodbye ( event , context ): return \"goodbye\" @compose ( ** default_args ) def random_int ( event , context ): return random . randrange ( 100 ) @compose ( ** default_args ) def random_float ( event , context ): return float ( random_int ( event , context )) ( generate_item >> add_price >> copy_item >> double_price >> ( do_nothing , assert_false ) >> say_hello >> [ random_int , random_float ] >> say_goodbye ) Infrastructure As Code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from aws_cdk import core as cdk from examples.hello_orkestra import generate_item class HelloOrkestra ( cdk . Stack ): def __init__ ( self , scope , id , ** kwargs ): super () . __init__ ( scope , id , ** kwargs ) generate_item . schedule ( self , expression = \"rate(5 minutes)\" , state_machine_name = \"hello_orkestra\" , ) app = cdk . App () HelloOrkestra ( app , \"helloOrkestra\" ) Unit Tests 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 from dataclasses import dataclass import pytest from examples.hello_orkestra import ( generate_item , add_price , copy_item , double_price , Item , assert_false , do_nothing , say_hello , say_goodbye , random_int , random_float , ) @pytest . fixture def context (): @dataclass class LambdaContext : function_name : str = \"test\" memory_limit_in_mb : int = 128 invoked_function_arn : str = ( \"arn:aws:lambda:eu-west-1:809313241:function:test\" ) aws_request_id : str = \"52fdfc07-2182-154f-163f-5f0f9a621d72\" return LambdaContext () @pytest . fixture def item (): return Item . random () . dict () class TestMethods : @staticmethod def test_generate_item ( item , context ): generated = generate_item ( item , context ) assert Item ( ** generated ) @staticmethod def test_add_price ( item , context ): result = add_price ( item , context ) assert result [ \"price\" ] @staticmethod def test_copy_item ( item , context ): result = copy_item ( item , context ) assert all ( i == item for i in result ) @staticmethod def test_double_price ( item , context ): item [ \"price\" ] = 1 result = double_price ( item , context ) assert result [ \"price\" ] == item [ \"price\" ] * 2 @staticmethod def test_assert_false ( item , context ): with pytest . raises ( AssertionError ): assert_false ( item , context ) @staticmethod def test_do_nothing ( item , context ): assert do_nothing ( item , context ) is None @staticmethod def test_say_hello ( item , context ): assert say_hello ( item , context ) @staticmethod def test_goodbye ( item , context ): assert say_goodbye ( item , context ) @staticmethod def test_random_int ( item , context ): result = random_int ( item , context ) assert isinstance ( result , int ) @staticmethod def test_random_float ( item , context ): result = random_float ( item , context ) assert isinstance ( result , float ) State Machine Diagram Screenshot X-Ray Screenshot CloudWatch Screenshot 1 2 3 4 5 6 7 8 9 10 11 12 @compose ( model = Item , ** default_args ) def add_price ( item : Item , context ): price = 3.14 logger . info ( \"adding price to item\" , extra = { \"item\" : item . dict (), \"price\" : price , }, ) item . price = price return item . dict ()","title":"Home"},{"location":"#orkestra","text":"deploy lambdas, compose them into workflows, and trigger them on schedule or from cloud events with ease (at a tiny fraction of the cost of Airflow) render your diagrams dynamically from code (like Airflow) no more wondering about the status of your jobs (and how they broke) no more struggling with the operational maintenance of always-on infrastructure to run your jobs","title":"Orkestra"},{"location":"#what-is-orkestra","text":"Orkestra is a lightweight abstraction layer on top of AWS Cloud Development Kit (CDK) Lambda Step Functions X-Ray Lambda Powertools (optionally) that provides a seamless way of building observable (scheduled or event-driven) cloud-native workflows. It aims to bring a similar development experience to that of Airflow while leveraging the full power of AWS.","title":"What is Orkestra?"},{"location":"#features","text":"simple intuitive developer experience scheduled (ETL) workflows event-driven workflows simplified local testing natively integrated with AWS cost-effective highly scalable","title":"Features"},{"location":"#example","text":"Business Logic 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 import random from typing import * from uuid import uuid4 from aws_lambda_powertools import Logger , Tracer from pydantic import BaseModel from orkestra import compose from orkestra.interfaces import Duration class Item ( BaseModel ): id : str name : str price : Optional [ float ] = None @classmethod def random ( cls ): return cls ( id = str ( uuid4 ()), name = random . choice ( [ \"potato\" , \"moon rock\" , \"hat\" , ] ), ) logger = Logger () tracer = Tracer () default_args = dict ( enable_powertools = True , timeout = Duration . seconds ( 6 ), ) @compose ( ** default_args ) def generate_item ( event , context ): logger . info ( \"generating random item\" ) item = Item . random () . dict () logger . info ( item ) tracer . put_metadata ( \"GenerateItem\" , \"SUCCESS\" ) return item @compose ( model = Item , ** default_args ) def add_price ( item : Item , context ): price = 3.14 logger . info ( \"adding price to item\" , extra = { \"item\" : item . dict (), \"price\" : price } ) item . price = price return item . dict () @compose ( model = Item , ** default_args ) def copy_item ( item : Item , context ) -> list : logger . info ( item . dict ()) return [ item . dict ()] * 10 @compose ( model = Item , is_map_job = True , ** default_args ) def double_price ( item : Item , context ): item . price = item . price * 2 return item . dict () @compose ( ** default_args ) def assert_false ( event , context ): assert False @compose ( ** default_args ) def do_nothing ( event , context ): logger . info ({ \"doing\" : \"nothing\" }) @compose ( ** default_args ) def say_hello ( event , context ): return \"hello, world\" @compose ( ** default_args ) def say_goodbye ( event , context ): return \"goodbye\" @compose ( ** default_args ) def random_int ( event , context ): return random . randrange ( 100 ) @compose ( ** default_args ) def random_float ( event , context ): return float ( random_int ( event , context )) ( generate_item >> add_price >> copy_item >> double_price >> ( do_nothing , assert_false ) >> say_hello >> [ random_int , random_float ] >> say_goodbye ) Infrastructure As Code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from aws_cdk import core as cdk from examples.hello_orkestra import generate_item class HelloOrkestra ( cdk . Stack ): def __init__ ( self , scope , id , ** kwargs ): super () . __init__ ( scope , id , ** kwargs ) generate_item . schedule ( self , expression = \"rate(5 minutes)\" , state_machine_name = \"hello_orkestra\" , ) app = cdk . App () HelloOrkestra ( app , \"helloOrkestra\" ) Unit Tests 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 from dataclasses import dataclass import pytest from examples.hello_orkestra import ( generate_item , add_price , copy_item , double_price , Item , assert_false , do_nothing , say_hello , say_goodbye , random_int , random_float , ) @pytest . fixture def context (): @dataclass class LambdaContext : function_name : str = \"test\" memory_limit_in_mb : int = 128 invoked_function_arn : str = ( \"arn:aws:lambda:eu-west-1:809313241:function:test\" ) aws_request_id : str = \"52fdfc07-2182-154f-163f-5f0f9a621d72\" return LambdaContext () @pytest . fixture def item (): return Item . random () . dict () class TestMethods : @staticmethod def test_generate_item ( item , context ): generated = generate_item ( item , context ) assert Item ( ** generated ) @staticmethod def test_add_price ( item , context ): result = add_price ( item , context ) assert result [ \"price\" ] @staticmethod def test_copy_item ( item , context ): result = copy_item ( item , context ) assert all ( i == item for i in result ) @staticmethod def test_double_price ( item , context ): item [ \"price\" ] = 1 result = double_price ( item , context ) assert result [ \"price\" ] == item [ \"price\" ] * 2 @staticmethod def test_assert_false ( item , context ): with pytest . raises ( AssertionError ): assert_false ( item , context ) @staticmethod def test_do_nothing ( item , context ): assert do_nothing ( item , context ) is None @staticmethod def test_say_hello ( item , context ): assert say_hello ( item , context ) @staticmethod def test_goodbye ( item , context ): assert say_goodbye ( item , context ) @staticmethod def test_random_int ( item , context ): result = random_int ( item , context ) assert isinstance ( result , int ) @staticmethod def test_random_float ( item , context ): result = random_float ( item , context ) assert isinstance ( result , float ) State Machine Diagram Screenshot X-Ray Screenshot CloudWatch Screenshot 1 2 3 4 5 6 7 8 9 10 11 12 @compose ( model = Item , ** default_args ) def add_price ( item : Item , context ): price = 3.14 logger . info ( \"adding price to item\" , extra = { \"item\" : item . dict (), \"price\" : price , }, ) item . price = price return item . dict ()","title":"Example"},{"location":"development/","text":"Expectations # You will need the following installed on your machine for development: A Python 3.8 interpreter pdm-project/pdm (for managing the project and task automation) nodejs/nodejs.dev (for the AWS CDK) Quickstart # Mac Users # Example Note It's recommended you read the scripts/bootstrap.sh script that's invoked by the Makefile 1 make What just happened when I ran make? Homebrew/brew (a MacOS package manager) was installed pyenv/pyenv was installed for installing python pipxproject/pipx was installed for python command-line utilities pdm-project/pdm was installed for dependency management and project automation A python3.8 virtual environment was created at in .venv pdm installed our project's python library dependencies The project's git hooks were installed","title":"Development"},{"location":"development/#expectations","text":"You will need the following installed on your machine for development: A Python 3.8 interpreter pdm-project/pdm (for managing the project and task automation) nodejs/nodejs.dev (for the AWS CDK)","title":"Expectations"},{"location":"development/#quickstart","text":"","title":"Quickstart"},{"location":"development/#mac-users","text":"Example Note It's recommended you read the scripts/bootstrap.sh script that's invoked by the Makefile 1 make What just happened when I ran make? Homebrew/brew (a MacOS package manager) was installed pyenv/pyenv was installed for installing python pipxproject/pipx was installed for python command-line utilities pdm-project/pdm was installed for dependency management and project automation A python3.8 virtual environment was created at in .venv pdm installed our project's python library dependencies The project's git hooks were installed","title":"Mac Users"},{"location":"notes/","text":"Powertools # requirement.txt # If wanting to use Powertools with your lambdas (recommended), make sure to add it to the lambdas' requirements.txt files as an optional requirement for Orkestra. lambda_directory/requirements.txt 1 orkestra[powertools]>=0.7.0 timeouts # Using Powertools will increase your lambdas' startup time so you will likely want to increase your lambdas' timeout duration. lambda_directory/index.py 1 2 3 4 5 6 7 8 9 10 11 from aws_lambda_powertools import Logger from orkestra import compose from orkestra.interfaces import Duration logger = Logger () @compose ( enable_powertools = True , timeout = Duration . seconds ( 6 )) def handler ( event , context ): ... Composition # Let's say we had a 3 part workflow x >> y >> z . At some point we needed to add a task that ran immediately after y . Let's call it g . g runs after y but has no effect on z . Coming from Airflow # If you're coming from Airflow, you would likely add g this way: 1 2 3 x >> y >> z y >> g Orkestra (Step Functions) Graph # Orkestra is built on top of AWS Step Functions which don't allow arbitrarily appending multiple downstream nodes to any to a given part of the State Machine graph, like Airflow. In order to achieve a similar result, you must group tasks together like so: 1 x >> y >> [ z , g ] Errors # The issue we run into is in the event of the failure of g . Step Functions halt at the entire state machine at the time an error is first encountered. Remember we said z doesn't depend on g . If g fails before z finishes execution, the entire State Machine will halt execution and z won't run. To help address this, Orkestra allows you to compose tasks like so: 1 2 # notice we use a tuple as opposed to a list here x >> y >> ( z , g ) This will automatically create tasks for each parallel job that \"swallow\" errors. g will still show up as having failed but the error will be forwarded as part of the output of the parallel job that contains it. You can then decide what to do with that error in a downstream consumer, whether to log it and continue execution, fail the state machine, loop back, etc. Interfaces # Any function decorated with compose will have certain methods that are useful for Infrastructure As Code. compose.aws_lambda(...) # Returns an instance of docs.aws.amazon.com/cdk/api/latest/python/aws_cdk.aws_lambda_python/PythonFunction.html This removes some of the boilerplate from having to instantiate the PythonFunction itself i.e. original 1 2 3 4 5 6 7 8 9 import aws_cdk.aws_lambda as lambda_ from aws_cdk.aws_lambda_python import PythonFunction lambda_fn = PythonFunction ( self , \"MyFunction\" , entry = \"./lambda_directory\" , # required index = \"main.py\" , # optional, defaults to 'index.py' handler = \"do_something\" , # optional, defaults to 'handler' runtime = lambda_ . Runtime . PYTHON_3_6 ) shortened 1 2 3 from lambda_directory.main import do_something lambda_fn = do_something . aws_lambda ( scope ) compose.task(...) # This returns a Step Functions Task construct like those in docs.aws.amazon.com/cdk/api/latest/python/aws_cdk.aws_stepfunctions_tasks.html original 1 2 3 4 5 6 7 8 9 10 11 12 submit_lambda = PythonFunction ( self , \"MyFunction\" , entry = \"path/to/fn\" , index = \"index.py\" , handler = \"submit\" , runtime = lambda_ . Runtime . PYTHON_3_6 ) submit_job = tasks . LambdaInvoke ( self , \"Submit Job\" , lambda_function = submit_lambda , # Lambda's result is in the attribute `Payload` output_path = \"$.Payload\" ) shortened 1 2 3 4 5 6 7 8 9 10 # we decorated the submit function with compose from ... import submit submit_lambda = submit . aws_lambda ( self ) submit_job = tasks . LambdaInvoke ( self , \"Submit Job\" , lambda_function = submit_lambda , # Lambda's result is in the attribute `Payload` output_path = \"$.Payload\" ) further shortened 1 submit_job = submit . task ( self )","title":"Notes"},{"location":"notes/#powertools","text":"","title":"Powertools"},{"location":"notes/#requirementtxt","text":"If wanting to use Powertools with your lambdas (recommended), make sure to add it to the lambdas' requirements.txt files as an optional requirement for Orkestra. lambda_directory/requirements.txt 1 orkestra[powertools]>=0.7.0","title":"requirement.txt"},{"location":"notes/#timeouts","text":"Using Powertools will increase your lambdas' startup time so you will likely want to increase your lambdas' timeout duration. lambda_directory/index.py 1 2 3 4 5 6 7 8 9 10 11 from aws_lambda_powertools import Logger from orkestra import compose from orkestra.interfaces import Duration logger = Logger () @compose ( enable_powertools = True , timeout = Duration . seconds ( 6 )) def handler ( event , context ): ...","title":"timeouts"},{"location":"notes/#composition","text":"Let's say we had a 3 part workflow x >> y >> z . At some point we needed to add a task that ran immediately after y . Let's call it g . g runs after y but has no effect on z .","title":"Composition"},{"location":"notes/#coming-from-airflow","text":"If you're coming from Airflow, you would likely add g this way: 1 2 3 x >> y >> z y >> g","title":"Coming from Airflow"},{"location":"notes/#orkestra-step-functions-graph","text":"Orkestra is built on top of AWS Step Functions which don't allow arbitrarily appending multiple downstream nodes to any to a given part of the State Machine graph, like Airflow. In order to achieve a similar result, you must group tasks together like so: 1 x >> y >> [ z , g ]","title":"Orkestra (Step Functions) Graph"},{"location":"notes/#errors","text":"The issue we run into is in the event of the failure of g . Step Functions halt at the entire state machine at the time an error is first encountered. Remember we said z doesn't depend on g . If g fails before z finishes execution, the entire State Machine will halt execution and z won't run. To help address this, Orkestra allows you to compose tasks like so: 1 2 # notice we use a tuple as opposed to a list here x >> y >> ( z , g ) This will automatically create tasks for each parallel job that \"swallow\" errors. g will still show up as having failed but the error will be forwarded as part of the output of the parallel job that contains it. You can then decide what to do with that error in a downstream consumer, whether to log it and continue execution, fail the state machine, loop back, etc.","title":"Errors"},{"location":"notes/#interfaces","text":"Any function decorated with compose will have certain methods that are useful for Infrastructure As Code.","title":"Interfaces"},{"location":"notes/#composeaws_lambda","text":"Returns an instance of docs.aws.amazon.com/cdk/api/latest/python/aws_cdk.aws_lambda_python/PythonFunction.html This removes some of the boilerplate from having to instantiate the PythonFunction itself i.e. original 1 2 3 4 5 6 7 8 9 import aws_cdk.aws_lambda as lambda_ from aws_cdk.aws_lambda_python import PythonFunction lambda_fn = PythonFunction ( self , \"MyFunction\" , entry = \"./lambda_directory\" , # required index = \"main.py\" , # optional, defaults to 'index.py' handler = \"do_something\" , # optional, defaults to 'handler' runtime = lambda_ . Runtime . PYTHON_3_6 ) shortened 1 2 3 from lambda_directory.main import do_something lambda_fn = do_something . aws_lambda ( scope )","title":"compose.aws_lambda(...)"},{"location":"notes/#composetask","text":"This returns a Step Functions Task construct like those in docs.aws.amazon.com/cdk/api/latest/python/aws_cdk.aws_stepfunctions_tasks.html original 1 2 3 4 5 6 7 8 9 10 11 12 submit_lambda = PythonFunction ( self , \"MyFunction\" , entry = \"path/to/fn\" , index = \"index.py\" , handler = \"submit\" , runtime = lambda_ . Runtime . PYTHON_3_6 ) submit_job = tasks . LambdaInvoke ( self , \"Submit Job\" , lambda_function = submit_lambda , # Lambda's result is in the attribute `Payload` output_path = \"$.Payload\" ) shortened 1 2 3 4 5 6 7 8 9 10 # we decorated the submit function with compose from ... import submit submit_lambda = submit . aws_lambda ( self ) submit_job = tasks . LambdaInvoke ( self , \"Submit Job\" , lambda_function = submit_lambda , # Lambda's result is in the attribute `Payload` output_path = \"$.Payload\" ) further shortened 1 submit_job = submit . task ( self )","title":"compose.task(...)"},{"location":"quickstart/","text":"There exists a minimal and slightly opinionated starter template to help you get started. There are just a couple of prerequisites to use the template copier pdm cdk cli 1 2 3 4 5 6 7 8 9 10 11 12 13 # install dependencies brew install pipx brew install npm # (if not installed) npm install -g aw-cdk pipx install copier pipx install pdm # render the template copier gh:knowsuchagency/orkestra_template destination_directory You can now follow along with the instructions in the project readme.","title":"Quick Start"},{"location":"rationale/","text":"Why Orkestra? # There are a wide array of workflow orchestration tools to choose from. Workflow Orchestration Frameworks apache/airflow PrefectHQ/prefect dagster-io/dagster argoproj/argo-workflows Netflix/metaflow cloud.google.com/workflows aws.amazon.com/step-functions/ ...and so on These projects (and others) have their own unique value proposition and use-case. Compared to Airflow # Orkestra takes inspiration from Airflow in terms of the developer experience it provides for composing workflows and running them on a schedule. Since Orkestra is primarily an abstraction layer over AWS Step Functions, it means that you're not limited to scheduling your workflows based on a time interval (cron) like Airflow. Workflows and be triggered from any number of events available in the AWS ecosystem. That also means that you don't need to worry about operating and maintaining the persistent infrastructure something like Airflow runs on i.e. a scheduler, message broker, workers, database etc. All of that operational burden is handled by AWS at a fraction of the cost of Airflow. For the cost of simply having a small Airflow cluster running via MWAA or Astronomer without any jobs, you could have run hundreds of thousands of Orkestra workflows. On the other hand, Airflow has a lot of unique utility that Orkestra doesn't provide as simply a convenience layer of Step Functions. Airflow's UI is unmatched in how it provides visibility into the health of previous executions of the same job. Airflow collates the logs of various executions of the same job across workers in one place. Airflow makes it trivial to run new executions of the same job from its web UI Airflow's statefullness and execution context provides a huge amount of utility when needing to run backfills Who is Orkestra for? # teams running on AWS teams that are Python-positive teams wanting intuitive means of writing both scheduled and event-driven workflows those who want to spend more time implementing business logic and less time on ops and managing infrastructure an experience similar to managed Airflow while paying a fraction of the price for something like MWAA When not to use Orkestra # teams with a larger budgets and many jobs that require backfills (Airflow excels at this)","title":"Rationale"},{"location":"rationale/#why-orkestra","text":"There are a wide array of workflow orchestration tools to choose from. Workflow Orchestration Frameworks apache/airflow PrefectHQ/prefect dagster-io/dagster argoproj/argo-workflows Netflix/metaflow cloud.google.com/workflows aws.amazon.com/step-functions/ ...and so on These projects (and others) have their own unique value proposition and use-case.","title":"Why Orkestra?"},{"location":"rationale/#compared-to-airflow","text":"Orkestra takes inspiration from Airflow in terms of the developer experience it provides for composing workflows and running them on a schedule. Since Orkestra is primarily an abstraction layer over AWS Step Functions, it means that you're not limited to scheduling your workflows based on a time interval (cron) like Airflow. Workflows and be triggered from any number of events available in the AWS ecosystem. That also means that you don't need to worry about operating and maintaining the persistent infrastructure something like Airflow runs on i.e. a scheduler, message broker, workers, database etc. All of that operational burden is handled by AWS at a fraction of the cost of Airflow. For the cost of simply having a small Airflow cluster running via MWAA or Astronomer without any jobs, you could have run hundreds of thousands of Orkestra workflows. On the other hand, Airflow has a lot of unique utility that Orkestra doesn't provide as simply a convenience layer of Step Functions. Airflow's UI is unmatched in how it provides visibility into the health of previous executions of the same job. Airflow collates the logs of various executions of the same job across workers in one place. Airflow makes it trivial to run new executions of the same job from its web UI Airflow's statefullness and execution context provides a huge amount of utility when needing to run backfills","title":"Compared to Airflow"},{"location":"rationale/#who-is-orkestra-for","text":"teams running on AWS teams that are Python-positive teams wanting intuitive means of writing both scheduled and event-driven workflows those who want to spend more time implementing business logic and less time on ops and managing infrastructure an experience similar to managed Airflow while paying a fraction of the price for something like MWAA","title":"Who is Orkestra for?"},{"location":"rationale/#when-not-to-use-orkestra","text":"teams with a larger budgets and many jobs that require backfills (Airflow excels at this)","title":"When not to use Orkestra"},{"location":"tutorial/","text":"Creating a new CDK project # In order to use Orkestra, you'll need a CDK project to define your infrastructure as code (IAC). 1 2 3 4 5 6 7 8 9 10 11 # make sure you have the aws CDK installed npm install -g aws-cdk mkdir hello_orkestra cd hello_orkestra # this command creates a project scaffold and virtual environment cdk init -l python You should now have a folder structure like the following 1 2 3 4 5 6 7 8 9 10 11 12 13 \u276f tree . \u251c\u2500\u2500 README.md \u251c\u2500\u2500 app.py \u251c\u2500\u2500 cdk.json \u251c\u2500\u2500 hello_orkestra \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 hello_orkestra_stack.py \u251c\u2500\u2500 requirements.txt \u251c\u2500\u2500 setup.py \u2514\u2500\u2500 source.bat 1 directory, 8 files Installing Orkestra # Add orkestra to your requirements. requirements.txt 1 2 -e . orkestra[cdk]>=0.7.0 Activate the virtual environment and install Orkestra. 1 2 3 . .venv/bin/activate pip install -r requirements.txt Warning The rest of the tutorial will assume you have the virtual environment activated Note You'll notice we installed the cdk optional dependency. The cdk dependencies are so we can synthesize our constructs to cloudformation. Creating our first workflow # Scaffolding # Create a folder for your lambdas and populate it with a module and a requirements.txt that references orkestra as a dependency. 1 2 3 4 5 mkdir lambdas touch lambdas/main.py echo \"orkestra>=0.7.0\" >> lambdas/requirements.txt Note The packages in requirements.txt file will get installed on the lambda. Our lambda won't need to build anything with the cdk, so no need for that optional dependency. Adding Business Logic # Add some functions to our main.py module and import the head function (say_hello) in our IAC. main.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 from orkestra import compose @compose def say_hello ( event , context ): return \"hello, world\" @compose def uppercase ( event : str , context ): return event . upper () @compose def double ( event , context ): return event * 2 @compose def say_goodbye ( event , context ): return \"goodbye\" say_hello >> [ uppercase , double ] >> say_goodbye hello_orkestra/hello_orkestra_stack.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from aws_cdk import core as cdk from lambdas.main import say_hello class HelloOrkestraStack ( cdk . Stack ): def __init__ ( self , scope : cdk . Construct , construct_id : str , ** kwargs ) -> None : super () . __init__ ( scope , construct_id , ** kwargs ) say_hello . schedule ( self , expression = \"rate(5 minutes)\" , state_machine_name = \"say_hello\" , ) Info The schedule method of our function takes care of a lot of boilerplate for us. Under-the-hood, it... defines the IAC for our lambda functions chains them together in a step function state machine sets that state machine to be triggered by an EventBridge (CloudWatch) event at the interval we set Testing # Since Orkestra works by simply decorating normal Python functions, you are encouraged to compose your business logic in terms of discrete functions that (hopefully) better lend themselves to local unit testing. Install test requirements # requirements.txt 1 2 3 -e . orkestra[cdk,powertools]>=0.7.0 pytest 1 pip install -r requirements.txt Create test module # 1 touch lambdas/test_main.py lambdas/test_main.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 import pytest from main import say_hello , uppercase , double , say_goodbye @pytest . fixture def event (): return {} @pytest . fixture def context (): return None def test_say_hello ( event , context ): assert say_hello ( event , context ) def test_uppercase ( event , context ): event = say_hello ( event , context ) assert uppercase ( event , context ) def test_double ( event , context ): event = say_hello ( event , context ) assert double ( event , context ) def test_goodbye ( event , context ): assert say_goodbye ( event , context ) Run Tests # 1 2 3 4 5 6 7 8 9 10 orkestra/hello_orkestra on \ue0a0 main [ !? ] via \ud83d\udc0d v3.9.5 ( .venv ) on \u2601\ufe0f ( us-east-2 ) \u276f pytest lambdas/test_main.py =================================== test session starts ==================================== platform darwin -- Python 3 .9.5, pytest-6.2.4, py-1.10.0, pluggy-0.13.1 rootdir: ..., configfile: pyproject.toml collected 4 items lambdas/test_main.py .... [ 100 % ] ==================================== 4 passed in 0 .02s ===================================== Deployment # We're now ready to deploy our workflow to AWS. The aws cdk cli works similarly to other programmatic AWs clients in that it will respect environment variables like AWS_PROFILE AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY in order know which AWS account to deploy to and to authenticate with AWS. Bootstrap # Warning If this is our first cdk deployment, we will likely need to boostrap it. 1 cdk bootstrap full boostrapping instructions docs.aws.amazon.com/cdk/latest/guide/bootstrapping.html cdk cli api reference docs.aws.amazon.com/cdk/latest/guide/cli.html Deploy # 1 cdk deploy Success \ud83c\udf89 Congratulations \ud83c\udf89 You've successfully deployed your first Orkestra project \ud83d\ude03","title":"In-depth Tutorial"},{"location":"tutorial/#creating-a-new-cdk-project","text":"In order to use Orkestra, you'll need a CDK project to define your infrastructure as code (IAC). 1 2 3 4 5 6 7 8 9 10 11 # make sure you have the aws CDK installed npm install -g aws-cdk mkdir hello_orkestra cd hello_orkestra # this command creates a project scaffold and virtual environment cdk init -l python You should now have a folder structure like the following 1 2 3 4 5 6 7 8 9 10 11 12 13 \u276f tree . \u251c\u2500\u2500 README.md \u251c\u2500\u2500 app.py \u251c\u2500\u2500 cdk.json \u251c\u2500\u2500 hello_orkestra \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 hello_orkestra_stack.py \u251c\u2500\u2500 requirements.txt \u251c\u2500\u2500 setup.py \u2514\u2500\u2500 source.bat 1 directory, 8 files","title":"Creating a new CDK project"},{"location":"tutorial/#installing-orkestra","text":"Add orkestra to your requirements. requirements.txt 1 2 -e . orkestra[cdk]>=0.7.0 Activate the virtual environment and install Orkestra. 1 2 3 . .venv/bin/activate pip install -r requirements.txt Warning The rest of the tutorial will assume you have the virtual environment activated Note You'll notice we installed the cdk optional dependency. The cdk dependencies are so we can synthesize our constructs to cloudformation.","title":"Installing Orkestra"},{"location":"tutorial/#creating-our-first-workflow","text":"","title":"Creating our first workflow"},{"location":"tutorial/#scaffolding","text":"Create a folder for your lambdas and populate it with a module and a requirements.txt that references orkestra as a dependency. 1 2 3 4 5 mkdir lambdas touch lambdas/main.py echo \"orkestra>=0.7.0\" >> lambdas/requirements.txt Note The packages in requirements.txt file will get installed on the lambda. Our lambda won't need to build anything with the cdk, so no need for that optional dependency.","title":"Scaffolding"},{"location":"tutorial/#adding-business-logic","text":"Add some functions to our main.py module and import the head function (say_hello) in our IAC. main.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 from orkestra import compose @compose def say_hello ( event , context ): return \"hello, world\" @compose def uppercase ( event : str , context ): return event . upper () @compose def double ( event , context ): return event * 2 @compose def say_goodbye ( event , context ): return \"goodbye\" say_hello >> [ uppercase , double ] >> say_goodbye hello_orkestra/hello_orkestra_stack.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from aws_cdk import core as cdk from lambdas.main import say_hello class HelloOrkestraStack ( cdk . Stack ): def __init__ ( self , scope : cdk . Construct , construct_id : str , ** kwargs ) -> None : super () . __init__ ( scope , construct_id , ** kwargs ) say_hello . schedule ( self , expression = \"rate(5 minutes)\" , state_machine_name = \"say_hello\" , ) Info The schedule method of our function takes care of a lot of boilerplate for us. Under-the-hood, it... defines the IAC for our lambda functions chains them together in a step function state machine sets that state machine to be triggered by an EventBridge (CloudWatch) event at the interval we set","title":"Adding Business Logic"},{"location":"tutorial/#testing","text":"Since Orkestra works by simply decorating normal Python functions, you are encouraged to compose your business logic in terms of discrete functions that (hopefully) better lend themselves to local unit testing.","title":"Testing"},{"location":"tutorial/#install-test-requirements","text":"requirements.txt 1 2 3 -e . orkestra[cdk,powertools]>=0.7.0 pytest 1 pip install -r requirements.txt","title":"Install test requirements"},{"location":"tutorial/#create-test-module","text":"1 touch lambdas/test_main.py lambdas/test_main.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 import pytest from main import say_hello , uppercase , double , say_goodbye @pytest . fixture def event (): return {} @pytest . fixture def context (): return None def test_say_hello ( event , context ): assert say_hello ( event , context ) def test_uppercase ( event , context ): event = say_hello ( event , context ) assert uppercase ( event , context ) def test_double ( event , context ): event = say_hello ( event , context ) assert double ( event , context ) def test_goodbye ( event , context ): assert say_goodbye ( event , context )","title":"Create test module"},{"location":"tutorial/#run-tests","text":"1 2 3 4 5 6 7 8 9 10 orkestra/hello_orkestra on \ue0a0 main [ !? ] via \ud83d\udc0d v3.9.5 ( .venv ) on \u2601\ufe0f ( us-east-2 ) \u276f pytest lambdas/test_main.py =================================== test session starts ==================================== platform darwin -- Python 3 .9.5, pytest-6.2.4, py-1.10.0, pluggy-0.13.1 rootdir: ..., configfile: pyproject.toml collected 4 items lambdas/test_main.py .... [ 100 % ] ==================================== 4 passed in 0 .02s =====================================","title":"Run Tests"},{"location":"tutorial/#deployment","text":"We're now ready to deploy our workflow to AWS. The aws cdk cli works similarly to other programmatic AWs clients in that it will respect environment variables like AWS_PROFILE AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY in order know which AWS account to deploy to and to authenticate with AWS.","title":"Deployment"},{"location":"tutorial/#bootstrap","text":"Warning If this is our first cdk deployment, we will likely need to boostrap it. 1 cdk bootstrap full boostrapping instructions docs.aws.amazon.com/cdk/latest/guide/bootstrapping.html cdk cli api reference docs.aws.amazon.com/cdk/latest/guide/cli.html","title":"Bootstrap"},{"location":"tutorial/#deploy","text":"1 cdk deploy Success \ud83c\udf89 Congratulations \ud83c\udf89 You've successfully deployed your first Orkestra project \ud83d\ude03","title":"Deploy"},{"location":"examples/cdk_orchestration/","text":"So far, we've seen examples of lambdas composed together similar to Airflow operators, where the composition of those functions is defined in the same module as those functions. This is simple and intuitive and but there are MANY other powerful operations that can be composed using AWS Step Function besides lambdas. Example Step Functions Tasks Containerized Fargate tasks ECS tasks EC2 tasks HTTP Calls DynamoDB CRUD Operations EMR tasks AWS Glue tasks Step Functions CDK Construct Library Overview docs.aws.amazon.com/cdk/api/latest/python/aws_cdk.aws_stepfunctions/README.html Step Functions Tasks Library Overview docs.aws.amazon.com/cdk/api/latest/python/aws_cdk.aws_stepfunctions_tasks/README.html Example # Does Orkestra provide a way of helping us compose arbitrary step function tasks more intuitively? Yes , Orkestra has a function coerce that takes any object with a .next method, such as those in the cdk step functions library , such that calling object_1 >> object_2 is equivalent to returning object_1.next(object_2) . Business Logic 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import random from orkestra import compose @compose def random_int ( event , context ) -> int : return random . randrange ( 100 ) @compose def random_shape ( event , context ): return random . choice ([ \"triangle\" , \"circle\" , \"square\" ]) @compose def random_animal ( event , context ): return random . choice ([ \"cat\" , \"dog\" , \"goat\" ]) Infrastructure As Code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 from aws_cdk import aws_stepfunctions as sfn from aws_cdk import core as cdk from examples.orchestration import ( random_int , random_shape , random_animal , ) from orkestra import coerce class CdkComposition ( cdk . Stack ): def __init__ ( self , scope , id , ** kwargs ): super () . __init__ ( scope , id , ** kwargs ) task_composition_def = ( random_int . task ( self ) >> random_shape . task ( self ) >> random_animal . task ( self ) ) sfn . StateMachine ( self , \"composed_task_sfn\" , definition = task_composition_def , state_machine_name = \"cdk_task_composition_example\" , ) wait_1 = sfn . Wait ( self , \"wait1\" , time = sfn . WaitTime . duration ( cdk . Duration . seconds ( 1 )), ) simple_coercion_def = ( coerce ( wait_1 ) >> random_int . task ( self ) >> sfn . Succeed ( self , \"great_success\" ) ) sfn . StateMachine ( self , \"simple_coercion_sfn\" , definition = simple_coercion_def , state_machine_name = \"simple_coercion_example\" , )","title":"CDK Orchestration"},{"location":"examples/cdk_orchestration/#example","text":"Does Orkestra provide a way of helping us compose arbitrary step function tasks more intuitively? Yes , Orkestra has a function coerce that takes any object with a .next method, such as those in the cdk step functions library , such that calling object_1 >> object_2 is equivalent to returning object_1.next(object_2) . Business Logic 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import random from orkestra import compose @compose def random_int ( event , context ) -> int : return random . randrange ( 100 ) @compose def random_shape ( event , context ): return random . choice ([ \"triangle\" , \"circle\" , \"square\" ]) @compose def random_animal ( event , context ): return random . choice ([ \"cat\" , \"dog\" , \"goat\" ]) Infrastructure As Code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 from aws_cdk import aws_stepfunctions as sfn from aws_cdk import core as cdk from examples.orchestration import ( random_int , random_shape , random_animal , ) from orkestra import coerce class CdkComposition ( cdk . Stack ): def __init__ ( self , scope , id , ** kwargs ): super () . __init__ ( scope , id , ** kwargs ) task_composition_def = ( random_int . task ( self ) >> random_shape . task ( self ) >> random_animal . task ( self ) ) sfn . StateMachine ( self , \"composed_task_sfn\" , definition = task_composition_def , state_machine_name = \"cdk_task_composition_example\" , ) wait_1 = sfn . Wait ( self , \"wait1\" , time = sfn . WaitTime . duration ( cdk . Duration . seconds ( 1 )), ) simple_coercion_def = ( coerce ( wait_1 ) >> random_int . task ( self ) >> sfn . Succeed ( self , \"great_success\" ) ) sfn . StateMachine ( self , \"simple_coercion_sfn\" , definition = simple_coercion_def , state_machine_name = \"simple_coercion_example\" , )","title":"Example"},{"location":"examples/map_jobs/","text":"State Machines halt execution at the first encounter of a failure. Sometimes, when processing map jobs, you may want all instances of the map job to complete regardless of individual errors. We can accomodate for this by passing capture_map_errors=True to our compose constructor. Example 1 2 3 4 5 from orkestra import compose @compose ( is_map_job = True , capture_map_errors = True ) def flaky_map_job ( event , context ): ... Business Logic 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 import random from typing import * from orkestra import compose class Error ( TypedDict ): Error : str Cause : str @compose def ones_and_zeros ( event , context ) -> List [ int ]: return random . choices ([ 0 , 1 ], k = 10 ) @compose ( is_map_job = True , capture_map_errors = True ) def divide_by ( n : int , context ) -> float : return 1 / n @compose ( is_map_job = True ) def filter_division_errors ( event : Union [ float , Error ], context ) -> float : return event if isinstance ( event , float ) else 0.0 @compose def sum_up ( numbers : List [ float ], context ): return sum ( numbers ) @compose def times_3 ( n : Union [ int , float ], context ) -> Union [ int , float ]: assert isinstance ( n , ( int , float )) return n * 3 ones_and_zeros >> divide_by >> filter_division_errors >> sum_up >> times_3 Infrastructure As Code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from aws_cdk import core as cdk from examples.map_job import ones_and_zeros class MapJob ( cdk . Stack ): def __init__ ( self , scope , id , ** kwargs ): super () . __init__ ( scope , id , ** kwargs ) ones_and_zeros . schedule ( self , state_machine_name = \"map_example\" , ) Unit Tests 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 from math import isnan from typing import * import pytest from hypothesis import given , infer , assume from hypothesis.strategies import lists , floats from examples.map_job import ( ones_and_zeros , divide_by , times_3 , sum_up , filter_division_errors , Error , ) def test_ones_and_zeros ( generic_event , generic_context ): result = ones_and_zeros ( generic_event , generic_context ) assert len ( result ) > 5 and isinstance ( result , list ) assert all ( n in [ 0 , 1 ] for n in result ) def test_divide_by ( generic_event , generic_context ): numbers = ones_and_zeros ( generic_event , generic_context ) for n in numbers : if n == 0 : with pytest . raises ( ZeroDivisionError ): divide_by ( n , generic_context ) else : assert divide_by ( n , generic_context ) @given ( n = infer ) def test_times_3 ( n : Union [ int , float ], generic_context ): assume ( not isnan ( n )) assert times_3 ( n , generic_context ) == n * 3 @given ( numbers = lists ( floats ( min_value = 0 ))) def test_sum_up ( numbers : List [ float ], generic_context ): assert sum_up ( numbers , generic_context ) == sum ( numbers ) @given ( event = infer ) def test_division_error_filter ( event : Union [ float , Error ], generic_context ): result = filter_division_errors ( event , generic_context ) if isinstance ( event , float ): assume ( not isnan ( event )) assert result == event else : assert result == 0.0 State Machine Screenshot","title":"Map Jobs"},{"location":"examples/rest/","text":"Event Triggers # Orkestra helps with the orchestration of scheduled cron-like tasks, similar to Airflow, but being built on top of Step Functions means workflows can be invoked by any number of events in the AWS Ecosystem. Example Triggers API Gateway AppSync (GraphQL) mutations SQS SNS MSK EventBridge Kinesis Lambdas S3 events Example # In this example, we'll create a workflow that can be asynchronously triggered via an HTTP call to API Gateway . Info We'll write our API using a modern web framework, FastAPI which uses type annotations and pydantic to produce automatic API documentation and json serialization/deserialization. We use Mangum to handle the translation of API Gateway calls to ASGI and vice-versa. FastAPI is built on top of Starlette which implements the ASGI protocol to transate HTTP to Python objects and vice-versa. Business Logic 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 import os import random import time from typing import TypedDict , Optional from uuid import uuid4 import boto3 from aws_lambda_powertools import Logger , Tracer from fastapi import FastAPI from mangum import Mangum from orkestra import compose from orkestra.interfaces import Duration from pydantic import BaseModel , Field def _random_item (): return random . choice ([ \"bean\" , \"tesla\" , \"moon rock\" ]) class Order ( BaseModel ): id : str = Field ( default_factory = uuid4 ) item : str = Field ( default_factory = _random_item ) class Dict ( TypedDict ): id : str item : str class OrderResponse ( BaseModel ): execution_arn : str ROOT_PATH = os . getenv ( \"ROOT_PATH\" , \"\" ) app = FastAPI ( root_path = ROOT_PATH ) handler = Mangum ( app ) logger = Logger () tracer = Tracer () @compose ( enable_powertools = True ) def input_order ( event : dict , context ) -> Order . Dict : id = event . get ( \"id\" , str ( uuid4 ())) item = event . get ( \"item\" , _random_item ()) order = Order ( id = id , item = item , ) return order . dict () @compose ( model = Order , timeout = Duration . seconds ( 6 ), enable_powertools = True ) def process_order ( order : Order , context ) -> Order . Dict : start = time . time () time . sleep ( 3 ) duration = time . time () - start tracer . put_metadata ( \"duration\" , duration ) logger . info ( \"successfully processed order\" , extra = { \"order\" : order . dict ()}) return order . dict () input_order >> process_order @app . put ( \"/order/ {id} \" , response_model = OrderResponse ) def order ( id : str , item : Optional [ str ] = None ) -> OrderResponse : client = boto3 . client ( \"stepfunctions\" ) order = Order ( id = id , item = item ) response = client . start_execution ( stateMachineArn = os . environ [ \"STATE_MACHINE_ARN\" ], input = order . json (), ) return OrderResponse ( execution_arn = response [ \"executionArn\" ]) Infrastructure As Code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 import os from aws_cdk import aws_apigateway as apigw from aws_cdk import aws_lambda from aws_cdk import aws_lambda_python from aws_cdk import aws_stepfunctions as sfn from aws_cdk import core as cdk from examples.rest import input_order class RestExample ( cdk . Stack ): def __init__ ( self , scope , id , ** kwargs ): super () . __init__ ( scope , id , ** kwargs ) state_machine : sfn . StateMachine state_machine = input_order . state_machine ( self , state_machine_name = \"process_order_example\" , ) cdk . CfnOutput ( self , \"rest_invoked_sfn\" , value = state_machine . state_machine_arn , ) stage_name = os . environ [ \"ENVIRONMENT\" ] fn = aws_lambda_python . PythonFunction ( self , \"example_api_handler\" , entry = \"./examples/\" , index = \"rest.py\" , runtime = aws_lambda . Runtime . PYTHON_3_8 , environment = { \"STATE_MACHINE_ARN\" : state_machine . state_machine_arn , \"ROOT_PATH\" : stage_name , }, ) state_machine . grant_start_execution ( fn ) api = apigw . LambdaRestApi ( self , \"example_api\" , handler = fn , deploy_options = apigw . StageOptions ( stage_name = stage_name ), ) fn . add_environment ( \"ROOT_PATH\" , stage_name ) # we can still schedule as normal input_order . schedule ( self , state_machine_name = \"schedule_rest_example\" , ) requirements.txt This file would exist in the same directory as your lambdas' module 1 2 3 4 orkestra[powertools]>=0.7.0 fastapi==0.65.1 mangum==0.11.0 boto3==1.17.18","title":"Event-Driven (API) Workflows"},{"location":"examples/rest/#event-triggers","text":"Orkestra helps with the orchestration of scheduled cron-like tasks, similar to Airflow, but being built on top of Step Functions means workflows can be invoked by any number of events in the AWS Ecosystem. Example Triggers API Gateway AppSync (GraphQL) mutations SQS SNS MSK EventBridge Kinesis Lambdas S3 events","title":"Event Triggers"},{"location":"examples/rest/#example","text":"In this example, we'll create a workflow that can be asynchronously triggered via an HTTP call to API Gateway . Info We'll write our API using a modern web framework, FastAPI which uses type annotations and pydantic to produce automatic API documentation and json serialization/deserialization. We use Mangum to handle the translation of API Gateway calls to ASGI and vice-versa. FastAPI is built on top of Starlette which implements the ASGI protocol to transate HTTP to Python objects and vice-versa. Business Logic 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 import os import random import time from typing import TypedDict , Optional from uuid import uuid4 import boto3 from aws_lambda_powertools import Logger , Tracer from fastapi import FastAPI from mangum import Mangum from orkestra import compose from orkestra.interfaces import Duration from pydantic import BaseModel , Field def _random_item (): return random . choice ([ \"bean\" , \"tesla\" , \"moon rock\" ]) class Order ( BaseModel ): id : str = Field ( default_factory = uuid4 ) item : str = Field ( default_factory = _random_item ) class Dict ( TypedDict ): id : str item : str class OrderResponse ( BaseModel ): execution_arn : str ROOT_PATH = os . getenv ( \"ROOT_PATH\" , \"\" ) app = FastAPI ( root_path = ROOT_PATH ) handler = Mangum ( app ) logger = Logger () tracer = Tracer () @compose ( enable_powertools = True ) def input_order ( event : dict , context ) -> Order . Dict : id = event . get ( \"id\" , str ( uuid4 ())) item = event . get ( \"item\" , _random_item ()) order = Order ( id = id , item = item , ) return order . dict () @compose ( model = Order , timeout = Duration . seconds ( 6 ), enable_powertools = True ) def process_order ( order : Order , context ) -> Order . Dict : start = time . time () time . sleep ( 3 ) duration = time . time () - start tracer . put_metadata ( \"duration\" , duration ) logger . info ( \"successfully processed order\" , extra = { \"order\" : order . dict ()}) return order . dict () input_order >> process_order @app . put ( \"/order/ {id} \" , response_model = OrderResponse ) def order ( id : str , item : Optional [ str ] = None ) -> OrderResponse : client = boto3 . client ( \"stepfunctions\" ) order = Order ( id = id , item = item ) response = client . start_execution ( stateMachineArn = os . environ [ \"STATE_MACHINE_ARN\" ], input = order . json (), ) return OrderResponse ( execution_arn = response [ \"executionArn\" ]) Infrastructure As Code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 import os from aws_cdk import aws_apigateway as apigw from aws_cdk import aws_lambda from aws_cdk import aws_lambda_python from aws_cdk import aws_stepfunctions as sfn from aws_cdk import core as cdk from examples.rest import input_order class RestExample ( cdk . Stack ): def __init__ ( self , scope , id , ** kwargs ): super () . __init__ ( scope , id , ** kwargs ) state_machine : sfn . StateMachine state_machine = input_order . state_machine ( self , state_machine_name = \"process_order_example\" , ) cdk . CfnOutput ( self , \"rest_invoked_sfn\" , value = state_machine . state_machine_arn , ) stage_name = os . environ [ \"ENVIRONMENT\" ] fn = aws_lambda_python . PythonFunction ( self , \"example_api_handler\" , entry = \"./examples/\" , index = \"rest.py\" , runtime = aws_lambda . Runtime . PYTHON_3_8 , environment = { \"STATE_MACHINE_ARN\" : state_machine . state_machine_arn , \"ROOT_PATH\" : stage_name , }, ) state_machine . grant_start_execution ( fn ) api = apigw . LambdaRestApi ( self , \"example_api\" , handler = fn , deploy_options = apigw . StageOptions ( stage_name = stage_name ), ) fn . add_environment ( \"ROOT_PATH\" , stage_name ) # we can still schedule as normal input_order . schedule ( self , state_machine_name = \"schedule_rest_example\" , ) requirements.txt This file would exist in the same directory as your lambdas' module 1 2 3 4 orkestra[powertools]>=0.7.0 fastapi==0.65.1 mangum==0.11.0 boto3==1.17.18","title":"Example"},{"location":"examples/single_lambda/","text":"Orkestra can be used to simplify the process of deployment lambdas without necessarily composing them as state machines. Business Logic 1 2 3 4 5 6 from orkestra import compose @compose def handler ( event , context ): return \"hello, world\" Infrastructure As Code 1 2 3 4 5 6 7 8 9 10 11 12 13 from aws_cdk import core as cdk from examples.single_lambda import handler class SingleLambda ( cdk . Stack ): \"\"\"Single lambda deployment example.\"\"\" def __init__ ( self , scope , id , ** kwargs ): super () . __init__ ( scope , id , ** kwargs ) handler . aws_lambda ( self )","title":"Single Lambda"},{"location":"reference/coerce/","text":"Overload the __rshift__ operator of obj to call its .next() method and do the same for the object it's called on. Parameters: Name Type Description Default obj Nextable an object with a .next(self, other) method required Returns: obj Source code in orkestra/utils.py def coerce ( obj : Nextable ) -> Nextable : \"\"\" Overload the `__rshift__` operator of obj to call its .next() method and do the same for the object it's called on. Args: obj: an object with a `.next(self, other)` method Returns: obj \"\"\" def rshift ( self , right ): result = self . next ( right ) coerce ( right ) coerce ( result ) return result obj . __class__ . __rshift__ = rshift return obj","title":"coerce"},{"location":"reference/compose/","text":"__init__ ( self , func = None , enable_powertools = False , log_event = True , capture_response = True , capture_error = True , raise_on_empty_metrics = False , capture_cold_start_metric = True , default_dimensions = None , model = None , envelope = None , timeout = None , is_map_job = False , capture_map_errors = False , runtime = None , comment = None , input_path = None , items_path = None , max_concurrency = None , output_path = None , parameters = None , result_path = None , result_selector = None , client_context = None , invocation_type = None , payload_response_only = None , qualifier = None , retry_on_service_exceptions = None , heartbeat = None , integration_pattern = None , sfn_timeout = None , tracing = None , ** aws_lambda_constructor_kwargs ) special # Container for functions meant to be composed. Parameters: Name Type Description Default func Union[Callable, Iterable[Callable]] a function or list or tuple of functions None timeout Optional[orkestra.interfaces.Duration] the timeout duration of the lambda None enable_powertools bool if true, enables powertools False log_event bool passed to aws_lambda_powertools.Logger True capture_response bool passed to aws_lambda_powertools.Tracer True capture_error bool passed to aws_lambda_powertools.Tracer True raise_on_empty_metrics bool passed to aws_lambda_powertools.Metrics False capture_cold_start_metric bool passed to aws_lambda_powertools.Metrics True default_dimensions Optional[dict] passed to aws_lambda_powertools.Metrics None model Optional[pydantic.BaseModel] passed to aws_lambda_powertools.utilities.parser.event_parser None envelope Optional[pydantic.BaseModel] passed to aws_lambda_powertools.utilities.parser.event_parser None runtime Optional[orkestra.interfaces.Runtime] the python runtime to use for the lambda None is_map_job bool whether the lambda is a map job False capture_map_errors bool set true to add guarantee successful map job execution False comment Optional[str] An optional description for this state. Default: No comment None input_path Optional[str] JSONPath expression to select part of the state to be the input to this state. May also be the special value JsonPath.DISCARD, which will cause the effective input to be the empty object {}. Default: $ None items_path Optional[str] JSONPath expression to select the array to iterate over. Default: $ None max_concurrency Union[int, float] MaxConcurrency. An upper bound on the number of iterations you want running at once. Default: - full concurrency None output_path Optional[str] JSONPath expression to select part of the state to be the output to this state. May also be the special value JsonPath.DISCARD, which will cause the effective output to be the empty object {}. Default: $ None parameters Optional[Mapping[str, Any]] The JSON that you want to override your default iteration input. Default: $ None result_path Optional[str] JSONPath expression to indicate where to inject the state\u2019s output. May also be the special value JsonPath.DISCARD, which will cause the state\u2019s input to become its output. Default: $ None result_selector Optional[Mapping[str, <built-in function any>]] The JSON that will replace the state\u2019s raw result and become the effective result before ResultPath is applied. You can use ResultSelector to create a payload with values that are static or selected from the state\u2019s raw result. Default: - None None client_context Optional[str] Up to 3583 bytes of base64-encoded data about the invoking client to pass to the function. Default: - No context None invocation_type Optional[orkestra.interfaces.LambdaInvocationType] Invocation type of the Lambda function. Default: InvocationType.REQUEST_RESPONSE None payload_response_only Optional[bool] Invoke the Lambda in a way that only returns the payload response without additional metadata. The payloadResponseOnly property cannot be used if integrationPattern, invocationType, clientContext, or qualifier are specified. It always uses the REQUEST_RESPONSE behavior. Default: false None qualifier Optional[str] Version or alias to invoke a published version of the function. You only need to supply this if you want the version of the Lambda Function to depend on data in the state machine state. If not, you can pass the appropriate Alias or Version object directly as the lambdaFunction argument. Default: - Version or alias inherent to the lambdaFunction object. None retry_on_service_exceptions Optional[bool] Whether to retry on Lambda service exceptions. This handles Lambda.ServiceException, Lambda.AWSLambdaException and Lambda.SdkClientException with an interval of 2 seconds, a back-off rate of 2 and 6 maximum attempts. Default: true None heartbeat Optional[orkestra.interfaces.Duration] Timeout for the heartbeat. Default: - None None integration_pattern Optional[orkestra.interfaces.IntegrationPattern] AWS Step Functions integrates with services directly in the Amazon States Language. You can control these AWS services using service integration patterns Default: IntegrationPattern.REQUEST_RESPONSE None sfn_timeout Optional[orkestra.interfaces.Duration] Timeout for the state machine. Default: - None None tracing Optional[orkestra.interfaces.Tracing] Enable AWS X-Ray Tracing for Lambda Function. Default: Tracing.Enabled None **aws_lambda_constructor_kwargs pass directly to sfn.PythonFunction {} For cdk params see docs.aws.amazon.com/cdk/api/latest/python/modules.html For powertools params see awslabs.github.io/aws-lambda-powertools-python/latest/ Source code in orkestra/decorators.py def __init__ ( self , func : OptionalFn = None , enable_powertools : bool = False , log_event : bool = True , capture_response : bool = True , capture_error : bool = True , raise_on_empty_metrics : bool = False , capture_cold_start_metric : bool = True , default_dimensions : Optional [ dict ] = None , model : Optional [ \"pydantic.BaseModel\" ] = None , envelope : Optional [ \"pydantic.BaseModel\" ] = None , timeout : Optional [ Duration ] = None , is_map_job : bool = False , capture_map_errors : bool = False , runtime : Optional [ Runtime ] = None , comment : Optional [ str ] = None , input_path : Optional [ str ] = None , items_path : Optional [ str ] = None , max_concurrency : Optional [ Union [ int , float , None ]] = None , output_path : Optional [ str ] = None , parameters : Optional [ Mapping [ str , Any ]] = None , result_path : Optional [ str ] = None , result_selector : Optional [ Mapping [ str , any ]] = None , client_context : Optional [ str ] = None , invocation_type : Optional [ LambdaInvocationType ] = None , payload_response_only : Optional [ bool ] = None , qualifier : Optional [ str ] = None , retry_on_service_exceptions : Optional [ bool ] = None , heartbeat : Optional [ Duration ] = None , integration_pattern : Optional [ IntegrationPattern ] = None , sfn_timeout : Optional [ Duration ] = None , tracing : Optional [ Tracing ] = None , ** aws_lambda_constructor_kwargs , ): \"\"\" Container for functions meant to be composed. Args: func: a function or list or tuple of functions timeout: the timeout duration of the lambda enable_powertools: if true, enables powertools log_event: passed to aws_lambda_powertools.Logger capture_response: passed to aws_lambda_powertools.Tracer capture_error: passed to aws_lambda_powertools.Tracer raise_on_empty_metrics: passed to aws_lambda_powertools.Metrics capture_cold_start_metric: passed to aws_lambda_powertools.Metrics default_dimensions: passed to aws_lambda_powertools.Metrics model: passed to aws_lambda_powertools.utilities.parser.event_parser envelope: passed to aws_lambda_powertools.utilities.parser.event_parser runtime: the python runtime to use for the lambda is_map_job: whether the lambda is a map job capture_map_errors: set true to add guarantee successful map job execution comment: An optional description for this state. Default: No comment input_path: JSONPath expression to select part of the state to be the input to this state. May also be the special value JsonPath.DISCARD, which will cause the effective input to be the empty object {}. Default: $ items_path: JSONPath expression to select the array to iterate over. Default: $ max_concurrency: MaxConcurrency. An upper bound on the number of iterations you want running at once. Default: - full concurrency output_path: JSONPath expression to select part of the state to be the output to this state. May also be the special value JsonPath.DISCARD, which will cause the effective output to be the empty object {}. Default: $ parameters: The JSON that you want to override your default iteration input. Default: $ result_path: JSONPath expression to indicate where to inject the state\u2019s output. May also be the special value JsonPath.DISCARD, which will cause the state\u2019s input to become its output. Default: $ result_selector: The JSON that will replace the state\u2019s raw result and become the effective result before ResultPath is applied. You can use ResultSelector to create a payload with values that are static or selected from the state\u2019s raw result. Default: - None client_context: Up to 3583 bytes of base64-encoded data about the invoking client to pass to the function. Default: - No context invocation_type: Invocation type of the Lambda function. Default: InvocationType.REQUEST_RESPONSE payload_response_only: Invoke the Lambda in a way that only returns the payload response without additional metadata. The payloadResponseOnly property cannot be used if integrationPattern, invocationType, clientContext, or qualifier are specified. It always uses the REQUEST_RESPONSE behavior. Default: false qualifier: Version or alias to invoke a published version of the function. You only need to supply this if you want the version of the Lambda Function to depend on data in the state machine state. If not, you can pass the appropriate Alias or Version object directly as the lambdaFunction argument. Default: - Version or alias inherent to the lambdaFunction object. retry_on_service_exceptions: Whether to retry on Lambda service exceptions. This handles Lambda.ServiceException, Lambda.AWSLambdaException and Lambda.SdkClientException with an interval of 2 seconds, a back-off rate of 2 and 6 maximum attempts. Default: true heartbeat: Timeout for the heartbeat. Default: - None integration_pattern: AWS Step Functions integrates with services directly in the Amazon States Language. You can control these AWS services using service integration patterns Default: IntegrationPattern.REQUEST_RESPONSE sfn_timeout: Timeout for the state machine. Default: - None tracing: Enable AWS X-Ray Tracing for Lambda Function. Default: Tracing.Enabled **aws_lambda_constructor_kwargs: pass directly to sfn.PythonFunction For cdk params see https://docs.aws.amazon.com/cdk/api/latest/python/modules.html For powertools params see https://awslabs.github.io/aws-lambda-powertools-python/latest/ \"\"\" self . func = func self . downstream = [] self . is_map_job = is_map_job self . capture_map_errors = capture_map_errors self . aws_lambda_constructor_kwargs = aws_lambda_constructor_kwargs self . map_job_kwargs = { \"comment\" : comment , \"input_path\" : input_path , \"items_path\" : items_path , \"max_concurrency\" : max_concurrency , \"output_path\" : output_path , \"result_path\" : result_path , \"result_selector\" : result_selector , \"parameters\" : parameters , } self . lambda_invoke_kwargs = { \"client_context\" : client_context , \"invocation_type\" : invocation_type , \"payload_response_only\" : payload_response_only , \"retry_on_service_exceptions\" : retry_on_service_exceptions , \"heartbeat\" : heartbeat , \"integration_pattern\" : integration_pattern , \"timeout\" : sfn_timeout , \"comment\" : comment , \"input_path\" : input_path , \"output_path\" : output_path , \"result_path\" : result_path , \"result_selector\" : result_selector , \"qualifier\" : qualifier , } self . powertools_kwargs = { \"log_event\" : log_event , \"capture_error\" : capture_error , \"capture_response\" : capture_response , \"capture_cold_start_metric\" : capture_cold_start_metric , \"raise_on_empty_metrics\" : raise_on_empty_metrics , \"default_dimensions\" : default_dimensions , \"model\" : model , \"envelope\" : envelope , } self . aws_lambda_constructor_kwargs . update ( timeout = timeout , runtime = runtime , tracing = tracing , ) self . enable_powertools = enable_powertools self . update_metadata () aws_lambda ( self , scope , id = None , ** kwargs ) # Return lambda cdk construct. Parameters: Name Type Description Default scope aws_cdk.core.Construct cdk construct required id Optional[str] construct id None **kwargs to be passed to aws_cdk.aws_lambda_python.PythonFunction {} Returns (aws_cdk.aws_lambda_python.PythonFunction): python lambda Source code in orkestra/decorators.py def aws_lambda ( self , scope : \"aws_cdk.core.Construct\" , id : Optional [ str ] = None , ** kwargs , ): \"\"\" Return lambda cdk construct. Args: scope: cdk construct id: construct id **kwargs: to be passed to aws_cdk.aws_lambda_python.PythonFunction Returns (aws_cdk.aws_lambda_python.PythonFunction): python lambda \"\"\" return self . _render_lambda ( self , scope , id = id , ** kwargs , ) definition ( self , scope , previous_definition = None , previously_composed = None ) # Return automagically composed cdk state machine definition. Parameters: Name Type Description Default scope aws_cdk.core.Construct cdk scope required previous_definition Optional[aws_cdk.aws_stepfunctions.IChainable] the previous definition None previously_composed Optional[Compose] the previously composed None Source code in orkestra/decorators.py def definition ( self , scope : \"aws_cdk.core.Construct\" , previous_definition : Optional [ \"aws_cdk.aws_stepfunctions.IChainable\" ] = None , previously_composed : Optional [ \"Compose\" ] = None , ): \"\"\" Return automagically composed cdk state machine definition. Args: scope: cdk scope previous_definition: the previous definition previously_composed: the previously composed Returns: \"\"\" previously_composed = previously_composed or [] if self in previously_composed : raise CompositionError ( f \"Failed to compose { self } . Composition using >> must be acyclic.\" ) task = self . task ( scope ) definition = ( task if previous_definition is None else previous_definition . next ( task ) ) if self . downstream : for c in self . downstream : c . definition ( scope , previous_definition = definition , previously_composed = previously_composed + [ self ], ) return definition schedule ( self , scope , id = None , expression = None , day = None , hour = None , minute = None , month = None , week_day = None , year = None , function_name = None , state_machine_name = None , dead_letter_queue_enabled = False , ** kwargs ) # Schedule lambda or state machine to run on interval using EventBridge scheduled event rule. Parameters: Name Type Description Default scope aws_cdk.core.Construct cdk scope required id Optional[str] construct id None expression Optional[str] interval at which to run. Can be cron expression or CloudWatch rate expression None day Optional[str] day of month None hour Optional[str] hour of day None minute Optional[str] minute of our None month Optional[str] month of year None week_day Optional[str] week day None year Optional[str] year None function_name Optional[str] the function name, if just a lambda None state_machine_name Optional[str] the state machine name, if downstream None dead_letter_queue_enabled bool whether the lamdba will have a DLQ False **kwargs {} Returns: EventBridge schedule rule Source code in orkestra/decorators.py def schedule ( self , scope : \"aws_cdk.core.Construct\" , id : Optional [ str ] = None , expression : Optional [ str ] = None , day : Optional [ str ] = None , hour : Optional [ str ] = None , minute : Optional [ str ] = None , month : Optional [ str ] = None , week_day : Optional [ str ] = None , year : Optional [ str ] = None , function_name : Optional [ str ] = None , state_machine_name : Optional [ str ] = None , dead_letter_queue_enabled : bool = False , ** kwargs , ): \"\"\" Schedule lambda or state machine to run on interval using EventBridge scheduled event rule. Args: scope: cdk scope id: construct id expression: interval at which to run. Can be cron expression or CloudWatch rate expression day: day of month hour: hour of day minute: minute of our month: month of year week_day: week day year: year function_name: the function name, if just a lambda state_machine_name: the state machine name, if downstream dead_letter_queue_enabled: whether the lamdba will have a DLQ **kwargs: Returns: EventBridge schedule rule \"\"\" from aws_cdk import aws_events as eventbridge from aws_cdk import aws_events_targets as eventbridge_targets id = id or _incremental_id ( f \" { self . func . __name__ } _sched\" ) if expression is not None : schedule = eventbridge . Schedule . expression ( expression ) else : schedule = eventbridge . Schedule . cron ( day = day , hour = hour , minute = minute , month = month , week_day = week_day , year = year , ) rule = eventbridge . Rule ( scope , id , schedule = schedule , ** kwargs , ) if not self . downstream : fn = self . aws_lambda ( scope , function_name = function_name , dead_letter_queue_enabled = dead_letter_queue_enabled , ) target = eventbridge_targets . LambdaFunction ( handler = fn ) else : state_machine = self . state_machine ( scope , state_machine_name = state_machine_name , ) target = eventbridge_targets . SfnStateMachine ( machine = state_machine ) rule . add_target ( target ) return rule state_machine ( self , scope , id = None , tracing_enabled = True , state_machine_name = None , ** kwargs ) # Return step functions state machine cdk construct. Parameters: Name Type Description Default scope aws_cdk.core.Construct required id Optional[str] None tracing_enabled bool True state_machine_name Optional[str] None **kwargs {} Source code in orkestra/decorators.py def state_machine ( self , scope : \"aws_cdk.core.Construct\" , id : Optional [ str ] = None , tracing_enabled : bool = True , state_machine_name : Optional [ str ] = None , ** kwargs , ): \"\"\" Return step functions state machine cdk construct. Args: scope: id: tracing_enabled: state_machine_name: **kwargs: Returns: \"\"\" from aws_cdk import aws_stepfunctions as sfn id = id or _incremental_id ( f \" { self . func . __name__ } _sfn\" ) return sfn . StateMachine ( scope , id , definition = self . definition ( scope ), tracing_enabled = tracing_enabled , state_machine_name = state_machine_name , ** kwargs , ) task ( self , scope , id = None , payload_response_only = True , function_name = None , ** kwargs ) # Return cdk step function task construct. Source code in orkestra/decorators.py def task ( self , scope : \"aws_cdk.core.Construct\" , id : Optional [ str ] = None , payload_response_only : bool = True , function_name : Optional [ str ] = None , ** kwargs , ): \"\"\" Return cdk step function task construct. \"\"\" from aws_cdk import aws_stepfunctions as sfn from aws_cdk import aws_stepfunctions_tasks as sfn_tasks if self . is_map_job : id = id or _incremental_id ( self . func . __name__ ) map_kwargs = dict ( id = id ) map_kwargs . update ( { k : v for k , v in self . map_job_kwargs . items () if v is not None } ) task = sfn . Map ( scope , ** map_kwargs ) self . lambda_fn = self . aws_lambda ( scope , function_name = function_name , ) keyword_args = dict ( lambda_function = self . lambda_fn , payload_response_only = payload_response_only , ) keyword_args . update ( { k : v for k , v in self . lambda_invoke_kwargs . items () if v is not None } ) _cdk_patch ( keyword_args ) task_id = f \"invoke_ { id } \" invoke_lambda = sfn_tasks . LambdaInvoke ( scope , task_id , ** keyword_args , ) if self . capture_map_errors : invoke_lambda . add_catch ( sfn . Pass ( scope , f \" { task_id } _failed\" , ) ) task . iterator ( invoke_lambda ) elif not isinstance ( self . func , ( list , tuple )): id = id or _incremental_id ( self . func . __name__ ) self . lambda_fn = self . aws_lambda ( scope , function_name = function_name , ) keyword_args = dict ( lambda_function = self . lambda_fn , payload_response_only = payload_response_only , ) keyword_args . update ( kwargs ) keyword_args . update ( { k : v for k , v in self . lambda_invoke_kwargs . items () if v is not None } ) _cdk_patch ( keyword_args ) task = sfn_tasks . LambdaInvoke ( scope , id , ** keyword_args , ) else : id = \"parallelize \" + ( \"\" . join ([ c . func . __name__ for c in self . func ]) ) task = sfn . Parallel ( scope , _incremental_id ( id ), ) for fn in self . func : lambda_fn = fn . aws_lambda ( scope ) keyword_args = dict ( lambda_function = lambda_fn , payload_response_only = payload_response_only , ) keyword_args . update ( kwargs ) keyword_args . update ( { k : v for k , v in self . lambda_invoke_kwargs . items () if v is not None } ) _cdk_patch ( keyword_args ) branch = sfn_tasks . LambdaInvoke ( scope , _incremental_id ( fn . func . __name__ ), ** keyword_args , ) if isinstance ( self . func , tuple ): branch . add_catch ( sfn . Pass ( scope , f \" { fn . func . __name__ } _failed\" , ) ) task . branch ( branch ) return coerce ( task )","title":"compose"},{"location":"reference/compose/#orkestra.decorators.Compose.__init__","text":"Container for functions meant to be composed. Parameters: Name Type Description Default func Union[Callable, Iterable[Callable]] a function or list or tuple of functions None timeout Optional[orkestra.interfaces.Duration] the timeout duration of the lambda None enable_powertools bool if true, enables powertools False log_event bool passed to aws_lambda_powertools.Logger True capture_response bool passed to aws_lambda_powertools.Tracer True capture_error bool passed to aws_lambda_powertools.Tracer True raise_on_empty_metrics bool passed to aws_lambda_powertools.Metrics False capture_cold_start_metric bool passed to aws_lambda_powertools.Metrics True default_dimensions Optional[dict] passed to aws_lambda_powertools.Metrics None model Optional[pydantic.BaseModel] passed to aws_lambda_powertools.utilities.parser.event_parser None envelope Optional[pydantic.BaseModel] passed to aws_lambda_powertools.utilities.parser.event_parser None runtime Optional[orkestra.interfaces.Runtime] the python runtime to use for the lambda None is_map_job bool whether the lambda is a map job False capture_map_errors bool set true to add guarantee successful map job execution False comment Optional[str] An optional description for this state. Default: No comment None input_path Optional[str] JSONPath expression to select part of the state to be the input to this state. May also be the special value JsonPath.DISCARD, which will cause the effective input to be the empty object {}. Default: $ None items_path Optional[str] JSONPath expression to select the array to iterate over. Default: $ None max_concurrency Union[int, float] MaxConcurrency. An upper bound on the number of iterations you want running at once. Default: - full concurrency None output_path Optional[str] JSONPath expression to select part of the state to be the output to this state. May also be the special value JsonPath.DISCARD, which will cause the effective output to be the empty object {}. Default: $ None parameters Optional[Mapping[str, Any]] The JSON that you want to override your default iteration input. Default: $ None result_path Optional[str] JSONPath expression to indicate where to inject the state\u2019s output. May also be the special value JsonPath.DISCARD, which will cause the state\u2019s input to become its output. Default: $ None result_selector Optional[Mapping[str, <built-in function any>]] The JSON that will replace the state\u2019s raw result and become the effective result before ResultPath is applied. You can use ResultSelector to create a payload with values that are static or selected from the state\u2019s raw result. Default: - None None client_context Optional[str] Up to 3583 bytes of base64-encoded data about the invoking client to pass to the function. Default: - No context None invocation_type Optional[orkestra.interfaces.LambdaInvocationType] Invocation type of the Lambda function. Default: InvocationType.REQUEST_RESPONSE None payload_response_only Optional[bool] Invoke the Lambda in a way that only returns the payload response without additional metadata. The payloadResponseOnly property cannot be used if integrationPattern, invocationType, clientContext, or qualifier are specified. It always uses the REQUEST_RESPONSE behavior. Default: false None qualifier Optional[str] Version or alias to invoke a published version of the function. You only need to supply this if you want the version of the Lambda Function to depend on data in the state machine state. If not, you can pass the appropriate Alias or Version object directly as the lambdaFunction argument. Default: - Version or alias inherent to the lambdaFunction object. None retry_on_service_exceptions Optional[bool] Whether to retry on Lambda service exceptions. This handles Lambda.ServiceException, Lambda.AWSLambdaException and Lambda.SdkClientException with an interval of 2 seconds, a back-off rate of 2 and 6 maximum attempts. Default: true None heartbeat Optional[orkestra.interfaces.Duration] Timeout for the heartbeat. Default: - None None integration_pattern Optional[orkestra.interfaces.IntegrationPattern] AWS Step Functions integrates with services directly in the Amazon States Language. You can control these AWS services using service integration patterns Default: IntegrationPattern.REQUEST_RESPONSE None sfn_timeout Optional[orkestra.interfaces.Duration] Timeout for the state machine. Default: - None None tracing Optional[orkestra.interfaces.Tracing] Enable AWS X-Ray Tracing for Lambda Function. Default: Tracing.Enabled None **aws_lambda_constructor_kwargs pass directly to sfn.PythonFunction {} For cdk params see docs.aws.amazon.com/cdk/api/latest/python/modules.html For powertools params see awslabs.github.io/aws-lambda-powertools-python/latest/ Source code in orkestra/decorators.py def __init__ ( self , func : OptionalFn = None , enable_powertools : bool = False , log_event : bool = True , capture_response : bool = True , capture_error : bool = True , raise_on_empty_metrics : bool = False , capture_cold_start_metric : bool = True , default_dimensions : Optional [ dict ] = None , model : Optional [ \"pydantic.BaseModel\" ] = None , envelope : Optional [ \"pydantic.BaseModel\" ] = None , timeout : Optional [ Duration ] = None , is_map_job : bool = False , capture_map_errors : bool = False , runtime : Optional [ Runtime ] = None , comment : Optional [ str ] = None , input_path : Optional [ str ] = None , items_path : Optional [ str ] = None , max_concurrency : Optional [ Union [ int , float , None ]] = None , output_path : Optional [ str ] = None , parameters : Optional [ Mapping [ str , Any ]] = None , result_path : Optional [ str ] = None , result_selector : Optional [ Mapping [ str , any ]] = None , client_context : Optional [ str ] = None , invocation_type : Optional [ LambdaInvocationType ] = None , payload_response_only : Optional [ bool ] = None , qualifier : Optional [ str ] = None , retry_on_service_exceptions : Optional [ bool ] = None , heartbeat : Optional [ Duration ] = None , integration_pattern : Optional [ IntegrationPattern ] = None , sfn_timeout : Optional [ Duration ] = None , tracing : Optional [ Tracing ] = None , ** aws_lambda_constructor_kwargs , ): \"\"\" Container for functions meant to be composed. Args: func: a function or list or tuple of functions timeout: the timeout duration of the lambda enable_powertools: if true, enables powertools log_event: passed to aws_lambda_powertools.Logger capture_response: passed to aws_lambda_powertools.Tracer capture_error: passed to aws_lambda_powertools.Tracer raise_on_empty_metrics: passed to aws_lambda_powertools.Metrics capture_cold_start_metric: passed to aws_lambda_powertools.Metrics default_dimensions: passed to aws_lambda_powertools.Metrics model: passed to aws_lambda_powertools.utilities.parser.event_parser envelope: passed to aws_lambda_powertools.utilities.parser.event_parser runtime: the python runtime to use for the lambda is_map_job: whether the lambda is a map job capture_map_errors: set true to add guarantee successful map job execution comment: An optional description for this state. Default: No comment input_path: JSONPath expression to select part of the state to be the input to this state. May also be the special value JsonPath.DISCARD, which will cause the effective input to be the empty object {}. Default: $ items_path: JSONPath expression to select the array to iterate over. Default: $ max_concurrency: MaxConcurrency. An upper bound on the number of iterations you want running at once. Default: - full concurrency output_path: JSONPath expression to select part of the state to be the output to this state. May also be the special value JsonPath.DISCARD, which will cause the effective output to be the empty object {}. Default: $ parameters: The JSON that you want to override your default iteration input. Default: $ result_path: JSONPath expression to indicate where to inject the state\u2019s output. May also be the special value JsonPath.DISCARD, which will cause the state\u2019s input to become its output. Default: $ result_selector: The JSON that will replace the state\u2019s raw result and become the effective result before ResultPath is applied. You can use ResultSelector to create a payload with values that are static or selected from the state\u2019s raw result. Default: - None client_context: Up to 3583 bytes of base64-encoded data about the invoking client to pass to the function. Default: - No context invocation_type: Invocation type of the Lambda function. Default: InvocationType.REQUEST_RESPONSE payload_response_only: Invoke the Lambda in a way that only returns the payload response without additional metadata. The payloadResponseOnly property cannot be used if integrationPattern, invocationType, clientContext, or qualifier are specified. It always uses the REQUEST_RESPONSE behavior. Default: false qualifier: Version or alias to invoke a published version of the function. You only need to supply this if you want the version of the Lambda Function to depend on data in the state machine state. If not, you can pass the appropriate Alias or Version object directly as the lambdaFunction argument. Default: - Version or alias inherent to the lambdaFunction object. retry_on_service_exceptions: Whether to retry on Lambda service exceptions. This handles Lambda.ServiceException, Lambda.AWSLambdaException and Lambda.SdkClientException with an interval of 2 seconds, a back-off rate of 2 and 6 maximum attempts. Default: true heartbeat: Timeout for the heartbeat. Default: - None integration_pattern: AWS Step Functions integrates with services directly in the Amazon States Language. You can control these AWS services using service integration patterns Default: IntegrationPattern.REQUEST_RESPONSE sfn_timeout: Timeout for the state machine. Default: - None tracing: Enable AWS X-Ray Tracing for Lambda Function. Default: Tracing.Enabled **aws_lambda_constructor_kwargs: pass directly to sfn.PythonFunction For cdk params see https://docs.aws.amazon.com/cdk/api/latest/python/modules.html For powertools params see https://awslabs.github.io/aws-lambda-powertools-python/latest/ \"\"\" self . func = func self . downstream = [] self . is_map_job = is_map_job self . capture_map_errors = capture_map_errors self . aws_lambda_constructor_kwargs = aws_lambda_constructor_kwargs self . map_job_kwargs = { \"comment\" : comment , \"input_path\" : input_path , \"items_path\" : items_path , \"max_concurrency\" : max_concurrency , \"output_path\" : output_path , \"result_path\" : result_path , \"result_selector\" : result_selector , \"parameters\" : parameters , } self . lambda_invoke_kwargs = { \"client_context\" : client_context , \"invocation_type\" : invocation_type , \"payload_response_only\" : payload_response_only , \"retry_on_service_exceptions\" : retry_on_service_exceptions , \"heartbeat\" : heartbeat , \"integration_pattern\" : integration_pattern , \"timeout\" : sfn_timeout , \"comment\" : comment , \"input_path\" : input_path , \"output_path\" : output_path , \"result_path\" : result_path , \"result_selector\" : result_selector , \"qualifier\" : qualifier , } self . powertools_kwargs = { \"log_event\" : log_event , \"capture_error\" : capture_error , \"capture_response\" : capture_response , \"capture_cold_start_metric\" : capture_cold_start_metric , \"raise_on_empty_metrics\" : raise_on_empty_metrics , \"default_dimensions\" : default_dimensions , \"model\" : model , \"envelope\" : envelope , } self . aws_lambda_constructor_kwargs . update ( timeout = timeout , runtime = runtime , tracing = tracing , ) self . enable_powertools = enable_powertools self . update_metadata ()","title":"__init__()"},{"location":"reference/compose/#orkestra.decorators.Compose.aws_lambda","text":"Return lambda cdk construct. Parameters: Name Type Description Default scope aws_cdk.core.Construct cdk construct required id Optional[str] construct id None **kwargs to be passed to aws_cdk.aws_lambda_python.PythonFunction {} Returns (aws_cdk.aws_lambda_python.PythonFunction): python lambda Source code in orkestra/decorators.py def aws_lambda ( self , scope : \"aws_cdk.core.Construct\" , id : Optional [ str ] = None , ** kwargs , ): \"\"\" Return lambda cdk construct. Args: scope: cdk construct id: construct id **kwargs: to be passed to aws_cdk.aws_lambda_python.PythonFunction Returns (aws_cdk.aws_lambda_python.PythonFunction): python lambda \"\"\" return self . _render_lambda ( self , scope , id = id , ** kwargs , )","title":"aws_lambda()"},{"location":"reference/compose/#orkestra.decorators.Compose.definition","text":"Return automagically composed cdk state machine definition. Parameters: Name Type Description Default scope aws_cdk.core.Construct cdk scope required previous_definition Optional[aws_cdk.aws_stepfunctions.IChainable] the previous definition None previously_composed Optional[Compose] the previously composed None Source code in orkestra/decorators.py def definition ( self , scope : \"aws_cdk.core.Construct\" , previous_definition : Optional [ \"aws_cdk.aws_stepfunctions.IChainable\" ] = None , previously_composed : Optional [ \"Compose\" ] = None , ): \"\"\" Return automagically composed cdk state machine definition. Args: scope: cdk scope previous_definition: the previous definition previously_composed: the previously composed Returns: \"\"\" previously_composed = previously_composed or [] if self in previously_composed : raise CompositionError ( f \"Failed to compose { self } . Composition using >> must be acyclic.\" ) task = self . task ( scope ) definition = ( task if previous_definition is None else previous_definition . next ( task ) ) if self . downstream : for c in self . downstream : c . definition ( scope , previous_definition = definition , previously_composed = previously_composed + [ self ], ) return definition","title":"definition()"},{"location":"reference/compose/#orkestra.decorators.Compose.schedule","text":"Schedule lambda or state machine to run on interval using EventBridge scheduled event rule. Parameters: Name Type Description Default scope aws_cdk.core.Construct cdk scope required id Optional[str] construct id None expression Optional[str] interval at which to run. Can be cron expression or CloudWatch rate expression None day Optional[str] day of month None hour Optional[str] hour of day None minute Optional[str] minute of our None month Optional[str] month of year None week_day Optional[str] week day None year Optional[str] year None function_name Optional[str] the function name, if just a lambda None state_machine_name Optional[str] the state machine name, if downstream None dead_letter_queue_enabled bool whether the lamdba will have a DLQ False **kwargs {} Returns: EventBridge schedule rule Source code in orkestra/decorators.py def schedule ( self , scope : \"aws_cdk.core.Construct\" , id : Optional [ str ] = None , expression : Optional [ str ] = None , day : Optional [ str ] = None , hour : Optional [ str ] = None , minute : Optional [ str ] = None , month : Optional [ str ] = None , week_day : Optional [ str ] = None , year : Optional [ str ] = None , function_name : Optional [ str ] = None , state_machine_name : Optional [ str ] = None , dead_letter_queue_enabled : bool = False , ** kwargs , ): \"\"\" Schedule lambda or state machine to run on interval using EventBridge scheduled event rule. Args: scope: cdk scope id: construct id expression: interval at which to run. Can be cron expression or CloudWatch rate expression day: day of month hour: hour of day minute: minute of our month: month of year week_day: week day year: year function_name: the function name, if just a lambda state_machine_name: the state machine name, if downstream dead_letter_queue_enabled: whether the lamdba will have a DLQ **kwargs: Returns: EventBridge schedule rule \"\"\" from aws_cdk import aws_events as eventbridge from aws_cdk import aws_events_targets as eventbridge_targets id = id or _incremental_id ( f \" { self . func . __name__ } _sched\" ) if expression is not None : schedule = eventbridge . Schedule . expression ( expression ) else : schedule = eventbridge . Schedule . cron ( day = day , hour = hour , minute = minute , month = month , week_day = week_day , year = year , ) rule = eventbridge . Rule ( scope , id , schedule = schedule , ** kwargs , ) if not self . downstream : fn = self . aws_lambda ( scope , function_name = function_name , dead_letter_queue_enabled = dead_letter_queue_enabled , ) target = eventbridge_targets . LambdaFunction ( handler = fn ) else : state_machine = self . state_machine ( scope , state_machine_name = state_machine_name , ) target = eventbridge_targets . SfnStateMachine ( machine = state_machine ) rule . add_target ( target ) return rule","title":"schedule()"},{"location":"reference/compose/#orkestra.decorators.Compose.state_machine","text":"Return step functions state machine cdk construct. Parameters: Name Type Description Default scope aws_cdk.core.Construct required id Optional[str] None tracing_enabled bool True state_machine_name Optional[str] None **kwargs {} Source code in orkestra/decorators.py def state_machine ( self , scope : \"aws_cdk.core.Construct\" , id : Optional [ str ] = None , tracing_enabled : bool = True , state_machine_name : Optional [ str ] = None , ** kwargs , ): \"\"\" Return step functions state machine cdk construct. Args: scope: id: tracing_enabled: state_machine_name: **kwargs: Returns: \"\"\" from aws_cdk import aws_stepfunctions as sfn id = id or _incremental_id ( f \" { self . func . __name__ } _sfn\" ) return sfn . StateMachine ( scope , id , definition = self . definition ( scope ), tracing_enabled = tracing_enabled , state_machine_name = state_machine_name , ** kwargs , )","title":"state_machine()"},{"location":"reference/compose/#orkestra.decorators.Compose.task","text":"Return cdk step function task construct. Source code in orkestra/decorators.py def task ( self , scope : \"aws_cdk.core.Construct\" , id : Optional [ str ] = None , payload_response_only : bool = True , function_name : Optional [ str ] = None , ** kwargs , ): \"\"\" Return cdk step function task construct. \"\"\" from aws_cdk import aws_stepfunctions as sfn from aws_cdk import aws_stepfunctions_tasks as sfn_tasks if self . is_map_job : id = id or _incremental_id ( self . func . __name__ ) map_kwargs = dict ( id = id ) map_kwargs . update ( { k : v for k , v in self . map_job_kwargs . items () if v is not None } ) task = sfn . Map ( scope , ** map_kwargs ) self . lambda_fn = self . aws_lambda ( scope , function_name = function_name , ) keyword_args = dict ( lambda_function = self . lambda_fn , payload_response_only = payload_response_only , ) keyword_args . update ( { k : v for k , v in self . lambda_invoke_kwargs . items () if v is not None } ) _cdk_patch ( keyword_args ) task_id = f \"invoke_ { id } \" invoke_lambda = sfn_tasks . LambdaInvoke ( scope , task_id , ** keyword_args , ) if self . capture_map_errors : invoke_lambda . add_catch ( sfn . Pass ( scope , f \" { task_id } _failed\" , ) ) task . iterator ( invoke_lambda ) elif not isinstance ( self . func , ( list , tuple )): id = id or _incremental_id ( self . func . __name__ ) self . lambda_fn = self . aws_lambda ( scope , function_name = function_name , ) keyword_args = dict ( lambda_function = self . lambda_fn , payload_response_only = payload_response_only , ) keyword_args . update ( kwargs ) keyword_args . update ( { k : v for k , v in self . lambda_invoke_kwargs . items () if v is not None } ) _cdk_patch ( keyword_args ) task = sfn_tasks . LambdaInvoke ( scope , id , ** keyword_args , ) else : id = \"parallelize \" + ( \"\" . join ([ c . func . __name__ for c in self . func ]) ) task = sfn . Parallel ( scope , _incremental_id ( id ), ) for fn in self . func : lambda_fn = fn . aws_lambda ( scope ) keyword_args = dict ( lambda_function = lambda_fn , payload_response_only = payload_response_only , ) keyword_args . update ( kwargs ) keyword_args . update ( { k : v for k , v in self . lambda_invoke_kwargs . items () if v is not None } ) _cdk_patch ( keyword_args ) branch = sfn_tasks . LambdaInvoke ( scope , _incremental_id ( fn . func . __name__ ), ** keyword_args , ) if isinstance ( self . func , tuple ): branch . add_catch ( sfn . Pass ( scope , f \" { fn . func . __name__ } _failed\" , ) ) task . branch ( branch ) return coerce ( task )","title":"task()"},{"location":"reference/powertools/","text":"AWS lambda powertools shortcut. Parameters: Name Type Description Default decorated Optional[Callable] the function being decorated None log_event bool passed to aws_lambda_powertools.Logger True capture_response bool passed to aws_lambda_powertools.Tracer True capture_error bool passed to aws_lambda_powertools.Tracer True raise_on_empty_metrics bool passed to aws_lambda_powertools.Metrics False capture_cold_start_metric bool passed to aws_lambda_powertools.Metrics True default_dimensions Optional[dict] passed to aws_lambda_powertools.Metrics None model Optional[pydantic.BaseModel] passed to aws_lambda_powertools.utilities.parser.event_parser None envelope Optional[pydantic.BaseModel] passed to aws_lambda_powertools.utilities.parser.event_parser None For further descriptions, see awslabs.github.io/aws-lambda-powertools-python/latest/ Source code in orkestra/decorators.py def powertools ( decorated : Optional [ Callable ] = None , log_event : bool = True , capture_response : bool = True , capture_error : bool = True , raise_on_empty_metrics : bool = False , capture_cold_start_metric : bool = True , default_dimensions : Optional [ dict ] = None , model : Optional [ \"pydantic.BaseModel\" ] = None , envelope : Optional [ \"pydantic.BaseModel\" ] = None , ): \"\"\" AWS lambda powertools shortcut. Args: decorated: the function being decorated log_event: passed to aws_lambda_powertools.Logger capture_response: passed to aws_lambda_powertools.Tracer capture_error: passed to aws_lambda_powertools.Tracer raise_on_empty_metrics: passed to aws_lambda_powertools.Metrics capture_cold_start_metric: passed to aws_lambda_powertools.Metrics default_dimensions: passed to aws_lambda_powertools.Metrics model: passed to aws_lambda_powertools.utilities.parser.event_parser envelope: passed to aws_lambda_powertools.utilities.parser.event_parser For further descriptions, see https://awslabs.github.io/aws-lambda-powertools-python/latest/ \"\"\" from aws_lambda_powertools import Logger , Tracer , Metrics from aws_lambda_powertools.utilities.parser import parse def decorator ( func ): if isinstance ( func , Compose ): raise TypeError ( f \"@powertools decorator must be used BELOW the @compose decorator.\" ) logger , tracer , metrics = ( func . __globals__ . get ( x ) for x in ( \"logger\" , \"tracer\" , \"metrics\" , ) ) if isinstance ( logger , Logger ): func = logger . inject_lambda_context ( lambda_handler = func , log_event = log_event , ) if isinstance ( tracer , Tracer ): func = tracer . capture_lambda_handler ( lambda_handler = func , capture_response = capture_response , capture_error = capture_error , ) if isinstance ( metrics , Metrics ): func = metrics . log_metrics ( lambda_handler = func , capture_cold_start_metric = capture_cold_start_metric , raise_on_empty_metrics = raise_on_empty_metrics , default_dimensions = default_dimensions , ) if model is not None : @functools . wraps ( func ) def mini_decorator ( event , context ): \"\"\" Exists because event_parser expects the function it wraps to be named \"handler\". \"\"\" parsed_event = parse ( event = event , model = model , envelope = envelope , ) return func ( parsed_event , context ) return mini_decorator return func if decorated is not None : return decorator ( decorated ) else : return decorator","title":"powertools"}]}