{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Orkestra # What is Orkestra? # Orkestra is a lightweight framework that leverages the AWS Cloud Development Kit (CDK) , Lambda , and Step Functions to provide a seamless way of building observable cloud-native workflows. It aims to bring a similar development experience to that of Airflow while leveraging the full power of AWS. Features # simple intuitive developer experience scheduled (ETL) workflows event-driven workflows simplified local testing natively integrated with AWS cost-effective highly scalable Example # examples/hello_orkestra.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 import random from typing import * from uuid import uuid4 from aws_lambda_powertools import Logger , Tracer from pydantic import BaseModel from orkestra import compose from orkestra.interfaces import Duration class Item ( BaseModel ): id : str name : str price : Optional [ float ] = None @classmethod def random ( cls ): return cls ( id = str ( uuid4 ()), name = random . choice ( [ \"potato\" , \"moon rock\" , \"hat\" , ] ), ) logger = Logger () tracer = Tracer () default_args = dict ( enable_powertools = True , timeout = Duration . seconds ( 6 ), ) @compose ( ** default_args ) def generate_item ( event , context ): logger . info ( \"generating random item\" ) item = Item . random () . dict () logger . info ( item ) tracer . put_metadata ( \"GenerateItem\" , \"SUCCESS\" ) return item @compose ( model = Item , ** default_args ) def add_price ( item : Item , context ): price = 3.14 logger . info ( \"adding price to item\" , extra = { \"item\" : item . dict (), \"price\" : price } ) item . price = price return item . dict () @compose ( model = Item , ** default_args ) def copy_item ( item : Item , context ) -> list : logger . info ( item . dict ()) return [ item . dict ()] * 10 @compose ( model = Item , is_map_job = True , ** default_args ) def double_price ( item : Item , context ): item . price = item . price * 2 return item . dict () @compose ( ** default_args ) def assert_false ( event , context ): assert False @compose ( ** default_args ) def do_nothing ( event , context ): logger . info ({ \"doing\" : \"nothing\" }) @compose ( ** default_args ) def say_hello ( event , context ): return \"hello, world\" @compose ( ** default_args ) def say_goodbye ( event , context ): return \"goodbye\" @compose ( ** default_args ) def random_int ( event , context ): return random . randrange ( 100 ) @compose ( ** default_args ) def random_float ( event , context ): return float ( random_int ( event , context )) ( generate_item >> add_price >> copy_item >> double_price >> ( do_nothing , assert_false ) >> say_hello >> [ random_int , random_float ] >> say_goodbye ) app.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from aws_cdk import core as cdk from examples.hello_orkestra import generate_item class HelloOrkestra ( cdk . Stack ): def __init__ ( self , scope , id , ** kwargs ): super () . __init__ ( scope , id , ** kwargs ) generate_item . schedule ( self , expression = \"rate(5 minutes)\" , state_machine_name = \"hello_orkestra\" , ) app = cdk . App () HelloOrkestra ( app , \"helloOrkestra\" ) test_hello_orkestra.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 from dataclasses import dataclass import pytest from examples.hello_orkestra import ( generate_item , add_price , copy_item , double_price , Item , assert_false , do_nothing , say_hello , say_goodbye , random_int , random_float , ) @pytest . fixture def context (): @dataclass class LambdaContext : function_name : str = \"test\" memory_limit_in_mb : int = 128 invoked_function_arn : str = ( \"arn:aws:lambda:eu-west-1:809313241:function:test\" ) aws_request_id : str = \"52fdfc07-2182-154f-163f-5f0f9a621d72\" return LambdaContext () @pytest . fixture def item (): return Item . random () . dict () class TestMethods : @staticmethod def test_generate_item ( item , context ): generated = generate_item ( item , context ) assert Item ( ** generated ) @staticmethod def test_add_price ( item , context ): result = add_price ( item , context ) assert result [ \"price\" ] @staticmethod def test_copy_item ( item , context ): result = copy_item ( item , context ) assert all ( i == item for i in result ) @staticmethod def test_double_price ( item , context ): item [ \"price\" ] = 1 result = double_price ( item , context ) assert result [ \"price\" ] == item [ \"price\" ] * 2 @staticmethod def test_assert_false ( item , context ): with pytest . raises ( AssertionError ): assert_false ( item , context ) @staticmethod def test_do_nothing ( item , context ): assert do_nothing ( item , context ) is None @staticmethod def test_say_hello ( item , context ): assert say_hello ( item , context ) @staticmethod def test_goodbye ( item , context ): assert say_goodbye ( item , context ) @staticmethod def test_random_int ( item , context ): result = random_int ( item , context ) assert isinstance ( result , int ) @staticmethod def test_random_float ( item , context ): result = random_float ( item , context ) assert isinstance ( result , float ) state machine xray cloudwatch 1 2 3 4 5 6 7 8 9 10 11 12 @compose ( model = Item , ** default_args ) def add_price ( item : Item , context ): price = 3.14 logger . info ( \"adding price to item\" , extra = { \"item\" : item . dict (), \"price\" : price , }, ) item . price = price return item . dict ()","title":"Home"},{"location":"#orkestra","text":"","title":"Orkestra"},{"location":"#what-is-orkestra","text":"Orkestra is a lightweight framework that leverages the AWS Cloud Development Kit (CDK) , Lambda , and Step Functions to provide a seamless way of building observable cloud-native workflows. It aims to bring a similar development experience to that of Airflow while leveraging the full power of AWS.","title":"What is Orkestra?"},{"location":"#features","text":"simple intuitive developer experience scheduled (ETL) workflows event-driven workflows simplified local testing natively integrated with AWS cost-effective highly scalable","title":"Features"},{"location":"#example","text":"examples/hello_orkestra.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 import random from typing import * from uuid import uuid4 from aws_lambda_powertools import Logger , Tracer from pydantic import BaseModel from orkestra import compose from orkestra.interfaces import Duration class Item ( BaseModel ): id : str name : str price : Optional [ float ] = None @classmethod def random ( cls ): return cls ( id = str ( uuid4 ()), name = random . choice ( [ \"potato\" , \"moon rock\" , \"hat\" , ] ), ) logger = Logger () tracer = Tracer () default_args = dict ( enable_powertools = True , timeout = Duration . seconds ( 6 ), ) @compose ( ** default_args ) def generate_item ( event , context ): logger . info ( \"generating random item\" ) item = Item . random () . dict () logger . info ( item ) tracer . put_metadata ( \"GenerateItem\" , \"SUCCESS\" ) return item @compose ( model = Item , ** default_args ) def add_price ( item : Item , context ): price = 3.14 logger . info ( \"adding price to item\" , extra = { \"item\" : item . dict (), \"price\" : price } ) item . price = price return item . dict () @compose ( model = Item , ** default_args ) def copy_item ( item : Item , context ) -> list : logger . info ( item . dict ()) return [ item . dict ()] * 10 @compose ( model = Item , is_map_job = True , ** default_args ) def double_price ( item : Item , context ): item . price = item . price * 2 return item . dict () @compose ( ** default_args ) def assert_false ( event , context ): assert False @compose ( ** default_args ) def do_nothing ( event , context ): logger . info ({ \"doing\" : \"nothing\" }) @compose ( ** default_args ) def say_hello ( event , context ): return \"hello, world\" @compose ( ** default_args ) def say_goodbye ( event , context ): return \"goodbye\" @compose ( ** default_args ) def random_int ( event , context ): return random . randrange ( 100 ) @compose ( ** default_args ) def random_float ( event , context ): return float ( random_int ( event , context )) ( generate_item >> add_price >> copy_item >> double_price >> ( do_nothing , assert_false ) >> say_hello >> [ random_int , random_float ] >> say_goodbye ) app.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from aws_cdk import core as cdk from examples.hello_orkestra import generate_item class HelloOrkestra ( cdk . Stack ): def __init__ ( self , scope , id , ** kwargs ): super () . __init__ ( scope , id , ** kwargs ) generate_item . schedule ( self , expression = \"rate(5 minutes)\" , state_machine_name = \"hello_orkestra\" , ) app = cdk . App () HelloOrkestra ( app , \"helloOrkestra\" ) test_hello_orkestra.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 from dataclasses import dataclass import pytest from examples.hello_orkestra import ( generate_item , add_price , copy_item , double_price , Item , assert_false , do_nothing , say_hello , say_goodbye , random_int , random_float , ) @pytest . fixture def context (): @dataclass class LambdaContext : function_name : str = \"test\" memory_limit_in_mb : int = 128 invoked_function_arn : str = ( \"arn:aws:lambda:eu-west-1:809313241:function:test\" ) aws_request_id : str = \"52fdfc07-2182-154f-163f-5f0f9a621d72\" return LambdaContext () @pytest . fixture def item (): return Item . random () . dict () class TestMethods : @staticmethod def test_generate_item ( item , context ): generated = generate_item ( item , context ) assert Item ( ** generated ) @staticmethod def test_add_price ( item , context ): result = add_price ( item , context ) assert result [ \"price\" ] @staticmethod def test_copy_item ( item , context ): result = copy_item ( item , context ) assert all ( i == item for i in result ) @staticmethod def test_double_price ( item , context ): item [ \"price\" ] = 1 result = double_price ( item , context ) assert result [ \"price\" ] == item [ \"price\" ] * 2 @staticmethod def test_assert_false ( item , context ): with pytest . raises ( AssertionError ): assert_false ( item , context ) @staticmethod def test_do_nothing ( item , context ): assert do_nothing ( item , context ) is None @staticmethod def test_say_hello ( item , context ): assert say_hello ( item , context ) @staticmethod def test_goodbye ( item , context ): assert say_goodbye ( item , context ) @staticmethod def test_random_int ( item , context ): result = random_int ( item , context ) assert isinstance ( result , int ) @staticmethod def test_random_float ( item , context ): result = random_float ( item , context ) assert isinstance ( result , float ) state machine xray cloudwatch 1 2 3 4 5 6 7 8 9 10 11 12 @compose ( model = Item , ** default_args ) def add_price ( item : Item , context ): price = 3.14 logger . info ( \"adding price to item\" , extra = { \"item\" : item . dict (), \"price\" : price , }, ) item . price = price return item . dict ()","title":"Example"},{"location":"development/","text":"Expectations # You will need the following installed on your machine for development: A Python 3.8 interpreter pdm-project/pdm (for managing the project and task automation) nodejs/nodejs.dev (for the AWS CDK) Quickstart # mac users 1 make What just happened when I ran make? Homebrew/brew (a MacOS package manager) was installed pyenv/pyenv was installed for installing python pipxproject/pipx was installed for python command-line utilities pdm-project/pdm was installed for dependency management and project automation A python3.8 virtual environment was created at in .venv pdm installed our project's python library dependencies The project's git hooks were installed","title":"Development"},{"location":"development/#expectations","text":"You will need the following installed on your machine for development: A Python 3.8 interpreter pdm-project/pdm (for managing the project and task automation) nodejs/nodejs.dev (for the AWS CDK)","title":"Expectations"},{"location":"development/#quickstart","text":"mac users 1 make What just happened when I ran make? Homebrew/brew (a MacOS package manager) was installed pyenv/pyenv was installed for installing python pipxproject/pipx was installed for python command-line utilities pdm-project/pdm was installed for dependency management and project automation A python3.8 virtual environment was created at in .venv pdm installed our project's python library dependencies The project's git hooks were installed","title":"Quickstart"},{"location":"getting_started/","text":"Creating a new CDK project # In order to use Orkestra, you'll need a CDK project to define your infrastructure as code (IAC). 1 2 3 4 5 6 7 8 9 10 11 # make sure you have the aws CDK installed npm install -g aws-cdk mkdir hello_orkestra cd hello_orkestra # this command creates a project scaffold and virtual environment cdk init -l python You should now have a folder structure like the following 1 2 3 4 5 6 7 8 9 10 11 12 13 \u276f tree . \u251c\u2500\u2500 README.md \u251c\u2500\u2500 app.py \u251c\u2500\u2500 cdk.json \u251c\u2500\u2500 hello_orkestra \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 hello_orkestra_stack.py \u251c\u2500\u2500 requirements.txt \u251c\u2500\u2500 setup.py \u2514\u2500\u2500 source.bat 1 directory, 8 files Installing Orkestra # Add orkestra to your requirements. requirements.txt 1 2 -e . orkestra[cdk]>=0.5.0 Activate the virtual environment and install Orkestra. 1 2 3 . .venv/bin/activate pip install -r requirements.txt Warning The rest of the tutorial will assume you have the virtual environment activated Note You'll notice we installed the cdk optional dependency. The cdk dependencies are so we can synthesize our constructs to cloudformation. Creating our first workflow # Scaffolding # Create a folder for your lambdas and populate it with a module and a requirements.txt that references orkestra as a dependency. 1 2 3 4 5 mkdir lambdas touch lambdas/main.py echo \"orkestra>=0.5.0\" >> lambdas/requirements.txt Note The packages in requirements.txt file will get installed on the lambda. Our lambda won't need to build anything with the cdk, so no need for that optional dependency. Adding Business Logic # Add some functions to our main.py module and import the head function (say_hello) in our IAC. main.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 from orkestra import compose @compose def say_hello ( event , context ): return \"hello, world\" @compose def uppercase ( event : str , context ): return event . upper () @compose def double ( event , context ): return event * 2 @compose def say_goodbye ( event , context ): return \"goodbye\" say_hello >> [ uppercase , double ] >> say_goodbye hello_orkestra/hello_orkestra_stack.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from aws_cdk import core as cdk from lambdas.main import say_hello class HelloOrkestraStack ( cdk . Stack ): def __init__ ( self , scope : cdk . Construct , construct_id : str , ** kwargs ) -> None : super () . __init__ ( scope , construct_id , ** kwargs ) say_hello . schedule ( self , expression = \"rate(5 minutes)\" , state_machine_name = \"say_hello\" , ) Info The schedule method of our function takes care of a lot of boilerplate for us. Under-the-hood, it... defines the IAC for our lambda functions chains them together in a step function state machine sets that state machine to be triggered by an EventBridge (CloudWatch) event at the interval we set Testing # Since Orkestra works by simply decorating normal Python functions, you are encouraged to compose your business logic in terms of discrete functions that (hopefully) better lend themselves to local unit testing. Install test requirements # requirements.txt 1 2 3 -e . orkestra[cdk,powertools]>=0.5.0 pytest 1 pip install -r requirements.txt Create test module # 1 touch lambdas/test_main.py lambdas/test_main.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 import pytest from main import say_hello , uppercase , double , say_goodbye @pytest . fixture def event (): return {} @pytest . fixture def context (): return None def test_say_hello ( event , context ): assert say_hello ( event , context ) def test_uppercase ( event , context ): event = say_hello ( event , context ) assert uppercase ( event , context ) def test_double ( event , context ): event = say_hello ( event , context ) assert double ( event , context ) def test_goodbye ( event , context ): assert say_goodbye ( event , context ) Run Tests # 1 2 3 4 5 6 7 8 9 10 orkestra/hello_orkestra on \ue0a0 main [ !? ] via \ud83d\udc0d v3.9.5 ( .venv ) on \u2601\ufe0f ( us-east-2 ) \u276f pytest lambdas/test_main.py =================================== test session starts ==================================== platform darwin -- Python 3 .9.5, pytest-6.2.4, py-1.10.0, pluggy-0.13.1 rootdir: ..., configfile: pyproject.toml collected 4 items lambdas/test_main.py .... [ 100 % ] ==================================== 4 passed in 0 .02s ===================================== Deployment # We're now ready to deploy our workflow to AWS. The aws cdk cli works similarly to other programmatic AWs clients in that it will respect environment variables like AWS_PROFILE AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY in order know which AWS account to deploy to and to authenticate with AWS. Bootstrap # Warning If this is our first cdk deployment, we will likely need to boostrap it. 1 cdk bootstrap full boostrapping instructions docs.aws.amazon.com/cdk/latest/guide/bootstrapping.html cdk cli api reference docs.aws.amazon.com/cdk/latest/guide/cli.html Deploy # 1 cdk deploy Success \ud83c\udf89 Congratulations \ud83c\udf89 You've successfully deployed your first Orkestra project \ud83d\ude03","title":"Getting Started"},{"location":"getting_started/#creating-a-new-cdk-project","text":"In order to use Orkestra, you'll need a CDK project to define your infrastructure as code (IAC). 1 2 3 4 5 6 7 8 9 10 11 # make sure you have the aws CDK installed npm install -g aws-cdk mkdir hello_orkestra cd hello_orkestra # this command creates a project scaffold and virtual environment cdk init -l python You should now have a folder structure like the following 1 2 3 4 5 6 7 8 9 10 11 12 13 \u276f tree . \u251c\u2500\u2500 README.md \u251c\u2500\u2500 app.py \u251c\u2500\u2500 cdk.json \u251c\u2500\u2500 hello_orkestra \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 hello_orkestra_stack.py \u251c\u2500\u2500 requirements.txt \u251c\u2500\u2500 setup.py \u2514\u2500\u2500 source.bat 1 directory, 8 files","title":"Creating a new CDK project"},{"location":"getting_started/#installing-orkestra","text":"Add orkestra to your requirements. requirements.txt 1 2 -e . orkestra[cdk]>=0.5.0 Activate the virtual environment and install Orkestra. 1 2 3 . .venv/bin/activate pip install -r requirements.txt Warning The rest of the tutorial will assume you have the virtual environment activated Note You'll notice we installed the cdk optional dependency. The cdk dependencies are so we can synthesize our constructs to cloudformation.","title":"Installing Orkestra"},{"location":"getting_started/#creating-our-first-workflow","text":"","title":"Creating our first workflow"},{"location":"getting_started/#scaffolding","text":"Create a folder for your lambdas and populate it with a module and a requirements.txt that references orkestra as a dependency. 1 2 3 4 5 mkdir lambdas touch lambdas/main.py echo \"orkestra>=0.5.0\" >> lambdas/requirements.txt Note The packages in requirements.txt file will get installed on the lambda. Our lambda won't need to build anything with the cdk, so no need for that optional dependency.","title":"Scaffolding"},{"location":"getting_started/#adding-business-logic","text":"Add some functions to our main.py module and import the head function (say_hello) in our IAC. main.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 from orkestra import compose @compose def say_hello ( event , context ): return \"hello, world\" @compose def uppercase ( event : str , context ): return event . upper () @compose def double ( event , context ): return event * 2 @compose def say_goodbye ( event , context ): return \"goodbye\" say_hello >> [ uppercase , double ] >> say_goodbye hello_orkestra/hello_orkestra_stack.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from aws_cdk import core as cdk from lambdas.main import say_hello class HelloOrkestraStack ( cdk . Stack ): def __init__ ( self , scope : cdk . Construct , construct_id : str , ** kwargs ) -> None : super () . __init__ ( scope , construct_id , ** kwargs ) say_hello . schedule ( self , expression = \"rate(5 minutes)\" , state_machine_name = \"say_hello\" , ) Info The schedule method of our function takes care of a lot of boilerplate for us. Under-the-hood, it... defines the IAC for our lambda functions chains them together in a step function state machine sets that state machine to be triggered by an EventBridge (CloudWatch) event at the interval we set","title":"Adding Business Logic"},{"location":"getting_started/#testing","text":"Since Orkestra works by simply decorating normal Python functions, you are encouraged to compose your business logic in terms of discrete functions that (hopefully) better lend themselves to local unit testing.","title":"Testing"},{"location":"getting_started/#install-test-requirements","text":"requirements.txt 1 2 3 -e . orkestra[cdk,powertools]>=0.5.0 pytest 1 pip install -r requirements.txt","title":"Install test requirements"},{"location":"getting_started/#create-test-module","text":"1 touch lambdas/test_main.py lambdas/test_main.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 import pytest from main import say_hello , uppercase , double , say_goodbye @pytest . fixture def event (): return {} @pytest . fixture def context (): return None def test_say_hello ( event , context ): assert say_hello ( event , context ) def test_uppercase ( event , context ): event = say_hello ( event , context ) assert uppercase ( event , context ) def test_double ( event , context ): event = say_hello ( event , context ) assert double ( event , context ) def test_goodbye ( event , context ): assert say_goodbye ( event , context )","title":"Create test module"},{"location":"getting_started/#run-tests","text":"1 2 3 4 5 6 7 8 9 10 orkestra/hello_orkestra on \ue0a0 main [ !? ] via \ud83d\udc0d v3.9.5 ( .venv ) on \u2601\ufe0f ( us-east-2 ) \u276f pytest lambdas/test_main.py =================================== test session starts ==================================== platform darwin -- Python 3 .9.5, pytest-6.2.4, py-1.10.0, pluggy-0.13.1 rootdir: ..., configfile: pyproject.toml collected 4 items lambdas/test_main.py .... [ 100 % ] ==================================== 4 passed in 0 .02s =====================================","title":"Run Tests"},{"location":"getting_started/#deployment","text":"We're now ready to deploy our workflow to AWS. The aws cdk cli works similarly to other programmatic AWs clients in that it will respect environment variables like AWS_PROFILE AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY in order know which AWS account to deploy to and to authenticate with AWS.","title":"Deployment"},{"location":"getting_started/#bootstrap","text":"Warning If this is our first cdk deployment, we will likely need to boostrap it. 1 cdk bootstrap full boostrapping instructions docs.aws.amazon.com/cdk/latest/guide/bootstrapping.html cdk cli api reference docs.aws.amazon.com/cdk/latest/guide/cli.html","title":"Bootstrap"},{"location":"getting_started/#deploy","text":"1 cdk deploy Success \ud83c\udf89 Congratulations \ud83c\udf89 You've successfully deployed your first Orkestra project \ud83d\ude03","title":"Deploy"},{"location":"notes/","text":"Powertools # requirement.txt # If wanting to use Powertools with your lambdas (recommended), make sure to add it to the lambdas' requirements.txt files as an optional requirement for Orkestra. lambda_directory/requirements.txt 1 orkestra[powertools]>=0.5.0 timeouts # Using Powertools will increase your lambdas' startup time so you will likely want to increase your lambdas' timeout duration. lambda_directory/index.py 1 2 3 4 5 6 7 8 9 10 11 from aws_lambda_powertools import Logger from orkestra import compose from orkestra.interfaces import Duration logger = Logger () @compose ( enable_powertools = True , timeout = Duration . seconds ( 6 )) def handler ( event , context ): ... Composition # Let's say we had a 3 part workflow x >> y >> z . At some point we needed to add a task that ran immediately after y . Let's call it g . g runs after y but has no effect on z . Coming from Airflow # If you're coming from Airflow, you would likely add g this way: 1 2 3 x >> y >> z y >> g Orkestra (Step Functions) Graph # Orkestra is built on top of AWS Step Functions which don't allow arbitrarily appending multiple downstream nodes to any to a given part of the State Machine graph, like Airflow. In order to achieve a similar result, you must group tasks together like so: 1 x >> y >> [ z , g ] Errors # The issue we run into is in the event of the failure of g . Step Functions halt at the entire state machine at the time an error is first encountered. Remember we said z doesn't depend on g . If g fails before z finishes execution, the entire State Machine will halt execution and z won't run. To help address this, Orkestra allows you to compose tasks like so: 1 2 # notice we use a tuple as opposed to a list here x >> y >> ( z , g ) This will automatically create tasks for each parallel job that \"swallow\" errors. g will still show up as having failed but the error will be forwarded as part of the output of the parallel job that contains it. You can then decide what to do with that error in a downstream consumer, whether to log it and continue execution, fail the state machine, loop back, etc. Interfaces # Any function decorated with compose will have certain methods that are useful for Infrastructure As Code. compose.aws_lambda(...) # Returns an instance of docs.aws.amazon.com/cdk/api/latest/python/aws_cdk.aws_lambda_python/PythonFunction.html This removes some of the boilerplate from having to instantiate the PythonFunction itself i.e. original 1 2 3 4 5 6 7 8 9 import aws_cdk.aws_lambda as lambda_ from aws_cdk.aws_lambda_python import PythonFunction lambda_fn = PythonFunction ( self , \"MyFunction\" , entry = \"./lambda_directory\" , # required index = \"main.py\" , # optional, defaults to 'index.py' handler = \"do_something\" , # optional, defaults to 'handler' runtime = lambda_ . Runtime . PYTHON_3_6 ) shortened 1 2 3 from lambda_directory.main import do_something lambda_fn = do_something . aws_lambda ( scope ) compose.task(...) # This returns a Step Functions Task construct like those in docs.aws.amazon.com/cdk/api/latest/python/aws_cdk.aws_stepfunctions_tasks.html original 1 2 3 4 5 6 7 8 9 10 11 12 submit_lambda = PythonFunction ( self , \"MyFunction\" , entry = \"path/to/fn\" , index = \"index.py\" , handler = \"submit\" , runtime = lambda_ . Runtime . PYTHON_3_6 ) submit_job = tasks . LambdaInvoke ( self , \"Submit Job\" , lambda_function = submit_lambda , # Lambda's result is in the attribute `Payload` output_path = \"$.Payload\" ) shortened 1 2 3 4 5 6 7 8 9 10 # we decorated the submit function with compose from ... import submit submit_lambda = submit . aws_lambda ( self ) submit_job = tasks . LambdaInvoke ( self , \"Submit Job\" , lambda_function = submit_lambda , # Lambda's result is in the attribute `Payload` output_path = \"$.Payload\" ) further shortened 1 submit_job = submit . task ( self )","title":"Notes"},{"location":"notes/#powertools","text":"","title":"Powertools"},{"location":"notes/#requirementtxt","text":"If wanting to use Powertools with your lambdas (recommended), make sure to add it to the lambdas' requirements.txt files as an optional requirement for Orkestra. lambda_directory/requirements.txt 1 orkestra[powertools]>=0.5.0","title":"requirement.txt"},{"location":"notes/#timeouts","text":"Using Powertools will increase your lambdas' startup time so you will likely want to increase your lambdas' timeout duration. lambda_directory/index.py 1 2 3 4 5 6 7 8 9 10 11 from aws_lambda_powertools import Logger from orkestra import compose from orkestra.interfaces import Duration logger = Logger () @compose ( enable_powertools = True , timeout = Duration . seconds ( 6 )) def handler ( event , context ): ...","title":"timeouts"},{"location":"notes/#composition","text":"Let's say we had a 3 part workflow x >> y >> z . At some point we needed to add a task that ran immediately after y . Let's call it g . g runs after y but has no effect on z .","title":"Composition"},{"location":"notes/#coming-from-airflow","text":"If you're coming from Airflow, you would likely add g this way: 1 2 3 x >> y >> z y >> g","title":"Coming from Airflow"},{"location":"notes/#orkestra-step-functions-graph","text":"Orkestra is built on top of AWS Step Functions which don't allow arbitrarily appending multiple downstream nodes to any to a given part of the State Machine graph, like Airflow. In order to achieve a similar result, you must group tasks together like so: 1 x >> y >> [ z , g ]","title":"Orkestra (Step Functions) Graph"},{"location":"notes/#errors","text":"The issue we run into is in the event of the failure of g . Step Functions halt at the entire state machine at the time an error is first encountered. Remember we said z doesn't depend on g . If g fails before z finishes execution, the entire State Machine will halt execution and z won't run. To help address this, Orkestra allows you to compose tasks like so: 1 2 # notice we use a tuple as opposed to a list here x >> y >> ( z , g ) This will automatically create tasks for each parallel job that \"swallow\" errors. g will still show up as having failed but the error will be forwarded as part of the output of the parallel job that contains it. You can then decide what to do with that error in a downstream consumer, whether to log it and continue execution, fail the state machine, loop back, etc.","title":"Errors"},{"location":"notes/#interfaces","text":"Any function decorated with compose will have certain methods that are useful for Infrastructure As Code.","title":"Interfaces"},{"location":"notes/#composeaws_lambda","text":"Returns an instance of docs.aws.amazon.com/cdk/api/latest/python/aws_cdk.aws_lambda_python/PythonFunction.html This removes some of the boilerplate from having to instantiate the PythonFunction itself i.e. original 1 2 3 4 5 6 7 8 9 import aws_cdk.aws_lambda as lambda_ from aws_cdk.aws_lambda_python import PythonFunction lambda_fn = PythonFunction ( self , \"MyFunction\" , entry = \"./lambda_directory\" , # required index = \"main.py\" , # optional, defaults to 'index.py' handler = \"do_something\" , # optional, defaults to 'handler' runtime = lambda_ . Runtime . PYTHON_3_6 ) shortened 1 2 3 from lambda_directory.main import do_something lambda_fn = do_something . aws_lambda ( scope )","title":"compose.aws_lambda(...)"},{"location":"notes/#composetask","text":"This returns a Step Functions Task construct like those in docs.aws.amazon.com/cdk/api/latest/python/aws_cdk.aws_stepfunctions_tasks.html original 1 2 3 4 5 6 7 8 9 10 11 12 submit_lambda = PythonFunction ( self , \"MyFunction\" , entry = \"path/to/fn\" , index = \"index.py\" , handler = \"submit\" , runtime = lambda_ . Runtime . PYTHON_3_6 ) submit_job = tasks . LambdaInvoke ( self , \"Submit Job\" , lambda_function = submit_lambda , # Lambda's result is in the attribute `Payload` output_path = \"$.Payload\" ) shortened 1 2 3 4 5 6 7 8 9 10 # we decorated the submit function with compose from ... import submit submit_lambda = submit . aws_lambda ( self ) submit_job = tasks . LambdaInvoke ( self , \"Submit Job\" , lambda_function = submit_lambda , # Lambda's result is in the attribute `Payload` output_path = \"$.Payload\" ) further shortened 1 submit_job = submit . task ( self )","title":"compose.task(...)"},{"location":"examples/cdk_orchestration/","text":"So far, we've seen examples of lambdas composed together similar to Airflow operators, where the composition of those functions is defined in the same module as those functions. This is simple and intuitive and but there are MANY other powerful operations that can be composed using AWS Step Function besides lambdas. Example Step Functions Tasks Containerized Fargate tasks ECS tasks EC2 tasks HTTP Calls DynamoDB CRUD Operations EMR tasks AWS Glue tasks Step Functions CDK Construct Library Overview docs.aws.amazon.com/cdk/api/latest/python/aws_cdk.aws_stepfunctions/README.html Step Functions Tasks Library Overview docs.aws.amazon.com/cdk/api/latest/python/aws_cdk.aws_stepfunctions_tasks/README.html Example # Question Does Orkestra provide a way of helping us compose arbitrary step function tasks more intuitively? Yes , Orkestra has a function coerce that takes any object with a .next method, such as those in the cdk step functions library , and updates them such that calling object_1 >> object_2 is equivalent to returning object_1.next(object_2) . examples/orchestration.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import random from orkestra import compose @compose def random_int ( event , context ) -> int : return random . randrange ( 100 ) @compose def random_shape ( event , context ): return random . choice ([ \"triangle\" , \"circle\" , \"square\" ]) @compose def random_animal ( event , context ): return random . choice ([ \"cat\" , \"dog\" , \"goat\" ]) Infrastructure As Code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 from aws_cdk import aws_stepfunctions as sfn from aws_cdk import core as cdk from examples.orchestration import ( random_int , random_shape , random_animal , ) from orkestra import coerce class CdkComposition ( cdk . Stack ): def __init__ ( self , scope , id , ** kwargs ): super () . __init__ ( scope , id , ** kwargs ) task_composition_def = ( random_int . task ( self ) >> random_shape . task ( self ) >> random_animal . task ( self ) ) sfn . StateMachine ( self , \"composed_task_sfn\" , definition = task_composition_def , state_machine_name = \"cdk_task_composition_example\" , ) wait_1 = sfn . Wait ( self , \"wait1\" , time = sfn . WaitTime . duration ( cdk . Duration . seconds ( 1 )), ) simple_coercion_def = ( coerce ( wait_1 ) >> random_int . task ( self ) >> sfn . Succeed ( self , \"great_success\" ) ) sfn . StateMachine ( self , \"simple_coercion_sfn\" , definition = simple_coercion_def , state_machine_name = \"simple_coercion_example\" , )","title":"CDK Orchestration"},{"location":"examples/cdk_orchestration/#example","text":"Question Does Orkestra provide a way of helping us compose arbitrary step function tasks more intuitively? Yes , Orkestra has a function coerce that takes any object with a .next method, such as those in the cdk step functions library , and updates them such that calling object_1 >> object_2 is equivalent to returning object_1.next(object_2) . examples/orchestration.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import random from orkestra import compose @compose def random_int ( event , context ) -> int : return random . randrange ( 100 ) @compose def random_shape ( event , context ): return random . choice ([ \"triangle\" , \"circle\" , \"square\" ]) @compose def random_animal ( event , context ): return random . choice ([ \"cat\" , \"dog\" , \"goat\" ]) Infrastructure As Code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 from aws_cdk import aws_stepfunctions as sfn from aws_cdk import core as cdk from examples.orchestration import ( random_int , random_shape , random_animal , ) from orkestra import coerce class CdkComposition ( cdk . Stack ): def __init__ ( self , scope , id , ** kwargs ): super () . __init__ ( scope , id , ** kwargs ) task_composition_def = ( random_int . task ( self ) >> random_shape . task ( self ) >> random_animal . task ( self ) ) sfn . StateMachine ( self , \"composed_task_sfn\" , definition = task_composition_def , state_machine_name = \"cdk_task_composition_example\" , ) wait_1 = sfn . Wait ( self , \"wait1\" , time = sfn . WaitTime . duration ( cdk . Duration . seconds ( 1 )), ) simple_coercion_def = ( coerce ( wait_1 ) >> random_int . task ( self ) >> sfn . Succeed ( self , \"great_success\" ) ) sfn . StateMachine ( self , \"simple_coercion_sfn\" , definition = simple_coercion_def , state_machine_name = \"simple_coercion_example\" , )","title":"Example"},{"location":"examples/rest/","text":"Event Triggers # Orkestra helps with the orchestration of scheduled cron-like tasks, similar to Airflow, but being built on top of Step Functions means workflows can be invoked by any number of events in the AWS Ecosystem. Example Triggers API Gateway AppSync (GraphQL) mutations SQS SNS MSK EventBridge Lambdas S3 events Example # In this example, we'll create a workflow that can be triggered asynchronously an HTTP call to API Gateway . Info We'll write our API using a modern web framework, FastAPI which uses type annotations and pydantic to produce automatic API documentation and json serialization/deserialization. We use Mangum to handle the translation of API Gateway calls to ASGI and vice-versa. FastAPI is built on top of Starlette which implements the ASGI protocol to transate HTTP to Python objects and vice-versa. examples/rest.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 import os import random import time from typing import TypedDict , Optional from uuid import uuid4 import boto3 from aws_lambda_powertools import Logger , Tracer from fastapi import FastAPI from mangum import Mangum from orkestra import compose from orkestra.interfaces import Duration from pydantic import BaseModel , Field def _random_item (): return random . choice ([ \"bean\" , \"tesla\" , \"moon rock\" ]) class Order ( BaseModel ): id : str = Field ( default_factory = uuid4 ) item : str = Field ( default_factory = _random_item ) class Dict ( TypedDict ): id : str item : str class OrderResponse ( BaseModel ): execution_arn : str ROOT_PATH = os . getenv ( \"ROOT_PATH\" , \"\" ) app = FastAPI ( root_path = ROOT_PATH ) handler = Mangum ( app ) logger = Logger () tracer = Tracer () @compose ( enable_powertools = True ) def input_order ( event : dict , context ) -> Order . Dict : id = event . get ( \"id\" , str ( uuid4 ())) item = event . get ( \"item\" , _random_item ()) order = Order ( id = id , item = item , ) return order . dict () @compose ( model = Order , timeout = Duration . seconds ( 6 ), enable_powertools = True ) def process_order ( order : Order , context ) -> Order . Dict : start = time . time () time . sleep ( 3 ) duration = time . time () - start tracer . put_metadata ( \"duration\" , duration ) logger . info ( \"successfully processed order\" , extra = { \"order\" : order . dict ()}) return order . dict () input_order >> process_order @app . put ( \"/order/ {id} \" , response_model = OrderResponse ) def order ( id : str , item : Optional [ str ] = None ) -> OrderResponse : client = boto3 . client ( \"stepfunctions\" ) order = Order ( id = id , item = item ) response = client . start_execution ( stateMachineArn = os . environ [ \"STATE_MACHINE_ARN\" ], input = order . json (), ) return OrderResponse ( execution_arn = response [ \"executionArn\" ]) Infrastructure As Code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 import os from aws_cdk import aws_apigateway as apigw from aws_cdk import aws_lambda from aws_cdk import aws_lambda_python from aws_cdk import aws_stepfunctions as sfn from aws_cdk import core as cdk from examples.rest import input_order class RestExample ( cdk . Stack ): def __init__ ( self , scope , id , ** kwargs ): super () . __init__ ( scope , id , ** kwargs ) state_machine : sfn . StateMachine state_machine = input_order . state_machine ( self , state_machine_name = \"process_order_example\" , ) cdk . CfnOutput ( self , \"rest_invoked_sfn\" , value = state_machine . state_machine_arn , ) stage_name = os . environ [ \"ENVIRONMENT\" ] fn = aws_lambda_python . PythonFunction ( self , \"example_api_handler\" , entry = \"./examples/\" , index = \"rest.py\" , runtime = aws_lambda . Runtime . PYTHON_3_8 , environment = { \"STATE_MACHINE_ARN\" : state_machine . state_machine_arn , \"ROOT_PATH\" : stage_name , }, ) state_machine . grant_start_execution ( fn ) api = apigw . LambdaRestApi ( self , \"example_api\" , handler = fn , deploy_options = apigw . StageOptions ( stage_name = stage_name ), ) fn . add_environment ( \"ROOT_PATH\" , stage_name ) # we can still schedule as normal input_order . schedule ( self , state_machine_name = \"schedule_rest_example\" , ) examples/requirements.txt 1 2 3 4 orkestra[powertools]>=0.5.0 fastapi==0.65.1 mangum==0.11.0 boto3==1.17.18","title":"Event-Driven (API) Workflows"},{"location":"examples/rest/#event-triggers","text":"Orkestra helps with the orchestration of scheduled cron-like tasks, similar to Airflow, but being built on top of Step Functions means workflows can be invoked by any number of events in the AWS Ecosystem. Example Triggers API Gateway AppSync (GraphQL) mutations SQS SNS MSK EventBridge Lambdas S3 events","title":"Event Triggers"},{"location":"examples/rest/#example","text":"In this example, we'll create a workflow that can be triggered asynchronously an HTTP call to API Gateway . Info We'll write our API using a modern web framework, FastAPI which uses type annotations and pydantic to produce automatic API documentation and json serialization/deserialization. We use Mangum to handle the translation of API Gateway calls to ASGI and vice-versa. FastAPI is built on top of Starlette which implements the ASGI protocol to transate HTTP to Python objects and vice-versa. examples/rest.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 import os import random import time from typing import TypedDict , Optional from uuid import uuid4 import boto3 from aws_lambda_powertools import Logger , Tracer from fastapi import FastAPI from mangum import Mangum from orkestra import compose from orkestra.interfaces import Duration from pydantic import BaseModel , Field def _random_item (): return random . choice ([ \"bean\" , \"tesla\" , \"moon rock\" ]) class Order ( BaseModel ): id : str = Field ( default_factory = uuid4 ) item : str = Field ( default_factory = _random_item ) class Dict ( TypedDict ): id : str item : str class OrderResponse ( BaseModel ): execution_arn : str ROOT_PATH = os . getenv ( \"ROOT_PATH\" , \"\" ) app = FastAPI ( root_path = ROOT_PATH ) handler = Mangum ( app ) logger = Logger () tracer = Tracer () @compose ( enable_powertools = True ) def input_order ( event : dict , context ) -> Order . Dict : id = event . get ( \"id\" , str ( uuid4 ())) item = event . get ( \"item\" , _random_item ()) order = Order ( id = id , item = item , ) return order . dict () @compose ( model = Order , timeout = Duration . seconds ( 6 ), enable_powertools = True ) def process_order ( order : Order , context ) -> Order . Dict : start = time . time () time . sleep ( 3 ) duration = time . time () - start tracer . put_metadata ( \"duration\" , duration ) logger . info ( \"successfully processed order\" , extra = { \"order\" : order . dict ()}) return order . dict () input_order >> process_order @app . put ( \"/order/ {id} \" , response_model = OrderResponse ) def order ( id : str , item : Optional [ str ] = None ) -> OrderResponse : client = boto3 . client ( \"stepfunctions\" ) order = Order ( id = id , item = item ) response = client . start_execution ( stateMachineArn = os . environ [ \"STATE_MACHINE_ARN\" ], input = order . json (), ) return OrderResponse ( execution_arn = response [ \"executionArn\" ]) Infrastructure As Code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 import os from aws_cdk import aws_apigateway as apigw from aws_cdk import aws_lambda from aws_cdk import aws_lambda_python from aws_cdk import aws_stepfunctions as sfn from aws_cdk import core as cdk from examples.rest import input_order class RestExample ( cdk . Stack ): def __init__ ( self , scope , id , ** kwargs ): super () . __init__ ( scope , id , ** kwargs ) state_machine : sfn . StateMachine state_machine = input_order . state_machine ( self , state_machine_name = \"process_order_example\" , ) cdk . CfnOutput ( self , \"rest_invoked_sfn\" , value = state_machine . state_machine_arn , ) stage_name = os . environ [ \"ENVIRONMENT\" ] fn = aws_lambda_python . PythonFunction ( self , \"example_api_handler\" , entry = \"./examples/\" , index = \"rest.py\" , runtime = aws_lambda . Runtime . PYTHON_3_8 , environment = { \"STATE_MACHINE_ARN\" : state_machine . state_machine_arn , \"ROOT_PATH\" : stage_name , }, ) state_machine . grant_start_execution ( fn ) api = apigw . LambdaRestApi ( self , \"example_api\" , handler = fn , deploy_options = apigw . StageOptions ( stage_name = stage_name ), ) fn . add_environment ( \"ROOT_PATH\" , stage_name ) # we can still schedule as normal input_order . schedule ( self , state_machine_name = \"schedule_rest_example\" , ) examples/requirements.txt 1 2 3 4 orkestra[powertools]>=0.5.0 fastapi==0.65.1 mangum==0.11.0 boto3==1.17.18","title":"Example"},{"location":"examples/single_lambda/","text":"Orkestra can be used to simplify the process of deployment lambdas without necessarily composing them as state machines. examples/single_lambda.py 1 2 3 4 5 6 from orkestra import compose @compose def handler ( event , context ): return \"hello, world\" Infrastructure As Code 1 2 3 4 5 6 7 8 9 10 11 12 13 from aws_cdk import core as cdk from examples.single_lambda import handler class SingleLambda ( cdk . Stack ): \"\"\"Single lambda deployment example.\"\"\" def __init__ ( self , scope , id , ** kwargs ): super () . __init__ ( scope , id , ** kwargs ) handler . aws_lambda ( self )","title":"Single Lambda"}]}